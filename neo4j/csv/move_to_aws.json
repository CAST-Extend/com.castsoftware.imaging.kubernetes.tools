[
    {
        "name": "Move to Amazon Web Services",
        "id": 1202174,
        "category": "START",
        "rationales": {
            "Agnostic": "Very specific move to cloud recommendations for customers targeting AWS Platform"
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [],
        "children": [
            1202094,
            1202180
        ]
    },
    {
        "name": "Oracle Database to Amazon Aurora with PostgreSQL: Data Type Remediation",
        "id": 1202175,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Recommendations to re-platform Oracle Database to AWS Aurora PostgreSQL that will require data type remediation."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Check if any violation of rules with TC 61045 and with tag AIP-M2C-DataType"
        },
        "description": "This rule checks all unsupported used Data types",
        "impacts": [
            "replatform"
        ],
        "effort": "moderate",
        "parents": [
            1202011
        ],
        "children": [
            1106020
        ]
    },
    {
        "name": "DB2 Database to Amazon Aurora with PostgreSQL",
        "id": 1202005,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Before migrating DB2 Database to Postgres on AWS Aurora, follwing checks need to be manual fixed since not supported on target DB service"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All checks of the TC: 61044"
        },
        "description": "",
        "impacts": [
            "replatform"
        ],
        "effort": null,
        "parents": [
            1202094
        ],
        "children": [
            1202023,
            1202025,
            1202081
        ]
    },
    {
        "name": "Mainframe Security Tools to Cloud Native Secrurity Service",
        "id": 1202010,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Mainframe applications often have specific security requirements. Identifying third-party security products early in the migration process allows organizations to assess their compatibility with the target environment and ensure seamless integration. It helps identify tools that need to be replaced by equivalent cloud-native services with likely corresponding code or configuration adaptations\n\nIdentifying third-party security products early allows also the migration team to assess the scope and complexity of required changes in application code and configuration to integrate new equivalent cloud services/tools"
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [
            1202067,
            1202077
        ],
        "children": [
            1202035,
            1202037
        ]
    },
    {
        "name": "Technologies Detection",
        "id": 1202096,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "The presence of the Focus, Assembler, Easytreive, Rexx code influences the migration strategy."
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [
            1202077
        ],
        "children": [
            1202078,
            1202079,
            1202080,
            1202095
        ]
    },
    {
        "name": "Data Migration to AWS Services",
        "id": 1202094,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "When considering mainframe modernization to AWS, Data migration to AWS data services can be a suitable starting point.\nData migration is, also, critical step in the overall modernization process, as it establishes the foundation for application transformation\n\nAWS provides services for the full data life cycle, from ingestion, to processing, storage, analysis, visualization, and automation. Migrating mainframe data from the mainframe’s relational, hierarchical, or legacy file-based data stores to agile AWS data lakes, data warehouses, or data stores allows quick integrate with various analytics and machine learning tools, enabling you to gain valuable insights from your data while keeping mainframe workloads."
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [
            1202174
        ],
        "children": [
            1202005,
            1202011,
            1202084,
            1202089
        ]
    },
    {
        "name": "SQL Server Database to Amazon Aurora with PostgreSQL: Syntax Remediation",
        "id": 1202179,
        "category": "BRANCHING-STEP",
        "rationales": {},
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": "low",
        "parents": [
            1202089
        ],
        "children": [
            1106108,
            1106110,
            1106112,
            1106132,
            1106134,
            1106136,
            1106138,
            1106140,
            1106144,
            1106146
        ]
    },
    {
        "name": "Mainframe to AWS with Automated Code Refactor for AWS",
        "id": 1202077,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Azure": "In order to prepare your Mainframe application to be transformed to Azure using Automated Code Refactoring solution (like Advanced..), we will identify dependencies, data access patterns, and other critical elements necessary for the migration process. Based on the analysis, the tools automatically refactor the mainframe code to make it compatible with the cloud environment and Azure services. This may involve converting legacy programming languages or data storage formats to cloud-native equivalents.",
            "Amazon Web Services": "In order to prepare your Mainframe application to be transformed by AWS Automated Code Refactor (like AWS Blue Age), we will identify dependencies, data access patterns, and other critical elements necessary for the migration process. Based on the analysis, the tools automatically refactor the mainframe code to make it compatible with the cloud environment and AWS services. This may involve converting legacy programming languages or data storage formats to cloud-native equivalents."
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [
            1202180
        ],
        "children": [
            1202002,
            1202006,
            1202008,
            1202009,
            1202010,
            1202013,
            1202018,
            1202019,
            1202044,
            1202059,
            1202066,
            1202084,
            1202096,
            1202099
        ]
    },
    {
        "name": "Cobol Programs candidate for AWS Lambda function conversion",
        "id": 1202002,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Not all programs are good use cases for Lambda. Technical characteristics make Lambda better suited for short-lived lightweight stateless functions. For this reason, some services are deployed in Lambda while others should be  deployed in containers or elastic compute service:\n\nFor example, Long-running batch processing cannot run in Lambda but they can run in containers And Online transactions or batch-specific short functions, on the other hand, can run in Lambda.\n\n\n\n",
            "Amazon Web Services": "It's possible to increase agility and cost efficiency further by targeting serverless functions in AWS Lambda.\n\nNot only is the monolith broken down into separate services, but the services become smaller functions with no need to manage servers or containers. With Lambda, there’s no charge when the code is not running.\n\nNot all programs are good use-cases for Lambda. Technical characteristics make Lambda better suited for short-lived lightweight stateless functions. For this reason, some services are deployed in Lambda while others are still deployed in containers or elastic compute.\n\nFor example, long-running batch processing cannot run in Lambda but they can run in containers. Online transactions or batch-specific short functions, on the other hand, can run in Lambda."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Cobol program belonging to one single transaction : \nMATCH (n:CDW {InternalType:'CAST_COBOL_SavedProgram'})-[p:Property]->(:ObjectProperty {Id:'1102000'}) where p.value in ['1', '2'] return n\n\n\nThe Entry Point of the transaction should have the property 'Number of Transaction' = 1\n\n"
        },
        "description": "The goal of this rule is to detect Cobol Program belonging to isolated transactions: These programs are good candidates for a manual rewrite as an AWS Lambda function or a standalone micro-Service",
        "impacts": [
            "replatform",
            "review"
        ],
        "effort": "high",
        "parents": [
            1202067,
            1202077
        ],
        "children": [
            1202001,
            1202027
        ]
    },
    {
        "name": "Cobol Syntax Checks -  Security checks before migration",
        "id": 1202021,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Cobol Statements and Syntaxes that may lead to security issues need to be reviewed before starting the migration to the cloud.\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "8480: http://rulesmanager/#:-4:255\n5062: http://rulesmanager/#:-4:5w \n5072: http://rulesmanager/#:-4:61"
        },
        "description": "Identifying Cobol Statements Leading to security issues",
        "impacts": [
            "rehost",
            "replatform",
            "review"
        ],
        "effort": "high",
        "parents": [
            1202004
        ],
        "children": [
            5062,
            5072,
            8480
        ]
    },
    {
        "name": "CICS Transactions processing system",
        "id": 1202059,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Azure": "Transitioning to Azure necessitates the phasing out of the mainframe CICS transaction processing system in favor of modern web applications.",
            "Amazon Web Services": "Transitioning to AWS necessitates the phasing out of the mainframe CICS transaction processing system in favor of modern web applications.\n\nEvaluate the existing CICS application is very important to \n- Identify the scope of the rewrite: which parts of the application need to be rewritten, which can be replaced \n- Determine the appropriate Aws services reproducing CICS services, such as Temporary Storage Queues, Temporary Data Queues or files access (multiple implementations are usually available, such as Amazon Kinesis Data Analytics, Amazon Simple Queue Service, or RabbitMQ for TD Queues),\n\nFor user-facing applications, the BMS screen description format is modernized to an Angular web",
            "Gougle Cloud Platform": "Transitioning to Google Cloud necessitates the phasing out of the mainframe CICS transaction processing system in favor of modern web applications."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "search for nodes with type is one of (CICS_MAP, CICS_BMS, CICS_MAPSET, CAST_IMS_MessageFormatService, CAST_IMS_MessageInputDescriptor, CAST_IMS_MessageOutputDescriptor, CAST_CICS_MapPrototype, CAST_CICS_MapSetPrototype) + callees to see which programs linked to these screens"
        },
        "description": "",
        "impacts": [
            "retire"
        ],
        "effort": null,
        "parents": [
            1202077
        ],
        "children": [
            1202058,
            1202063,
            1202152,
            1202153
        ]
    },
    {
        "name": "Sequential Files Storage Candidate for Systems file service",
        "id": 1202013,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Migrating Sequential datasets to sequential or indexed files stored in a file system is a recommended option for Mainframe data migration."
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [
            "replatform",
            "review"
        ],
        "effort": null,
        "parents": [
            1202067,
            1202077
        ],
        "children": [
            1202014,
            1202015,
            1202030,
            1202048
        ]
    },
    {
        "name": "Cobol Programs using IBM MQ communication Protocol",
        "id": 1202066,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Azure": "Identifying communication protocols for mainframe applications is an important step in the cloud migration process because it helps ensure that the application can continue to communicate effectively with other systems and applications once it is moved to the cloud.\n\nMessage queues are a common way for different applications to exchange data and communicate with each other in a mainframe environment. When migrating the application to the cloud, it's very important to identify any dependencies on specific message queue protocol(s), and evaluate the adherence of the application with this communication protocol.\nthis is very helpful to identify the replication service in a target cloud environment \n\nWhen moving to Azure, IBM MQ system is usually replicated with Azure Queue Storage Service or other MQ-specific connectors. All Cobol programs using IBM MQ utilities, publishing or consuming messages will require a minimum change/review of the connection APIs with the new cloud messaging service\n\n\nhttps://learn.microsoft.com/en-us/azure/architecture/example-scenario/mainframe/integrate-ibm-message-queues-azure\n\n\n\n",
            "Amazon Web Services": "Identifying communication protocols for mainframe applications is an important step in the cloud migration process because it helps ensure that the application can continue to communicate effectively with other systems and applications once it is moved to the cloud.\n\nMessage queues are a common way for different applications to exchange data and communicate with each other in a mainframe environment. When migrating the application to the cloud, it's very important to identify any dependencies on specific message queue protocol(s), and evaluate the adherence of the application with this communication protocol.\nthis is very helpful to identify the replication service in a target cloud environment \n\n\nWhen moving to AWS, the IBM MQ system is usually replicated with Amazon MQ Service. All Cobol programs using IBM MQ utilities, publishing or consuming messages will require a minimum change/review of the connection APIs with the new cloud messaging service",
            "Gougle Cloud Platform": "Identifying communication protocols for mainframe applications is an important step in the cloud migration process because it helps ensure that the application can continue to communicate effectively with other systems and applications once it is moved to the cloud.\n\nMessage queues are a common way for different applications to exchange data and communicate with each other in a mainframe environment. When migrating the application to the cloud, it's very important to identify any dependencies on specific message queue protocol(s), and evaluate the adherence of the application with this communication protocol.\nthis is very helpful to identify the replication service in a target cloud environment dates are needed to ensure smooth communication between the mainframe application and other systems in the cloud.\n\nWhen moving to GCP, IBM MQ system is usually replicated with Google Cloud Pub/Sub service. All Cobol programs using IBM MQ utilities, publishing or consuming messages will require a minimum change/review of the connection APIs with the new cloud messaging service\n\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Cobol Programs Calling MQ utilities: InternalType=CAST_COBOL_SavedProgram calling MQ utilities"
        },
        "description": "Identify all Cobol Programs using IBM MQSeries communication protocol.",
        "impacts": [
            "replatform",
            "review",
            "rehost"
        ],
        "effort": "none",
        "parents": [
            1202067,
            1202077
        ],
        "children": [
            1202020,
            1202049,
            1202050
        ]
    },
    {
        "name": "Files Storage Candidate for Cloud Relational Database",
        "id": 1202006,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "Mainframes support several types of physical data sets. These data sets can create various migration challenges, depending on your target application and architecture.\n\nMost Data sets files cannot be kept as is and must be replaced/converted into a relational database in the target platform. Identifying data sets before migration helps identify the ones that require conversion, and ensures that the appropriate conversion steps are taken into consideration including the review of the data access logic of the current application.\n\nWhen moving to AWS, Dataset files as VSAM which used to store and manage data in sequential order are, usually, replicated to Amazon RDS \nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/migrate-and-replicate-vsam-files-to-amazon-rds-or-amazon-msk-using-connect-from-precisely.html\n"
        },
        "remediations": {},
        "populations": {},
        "description": "This set of rules will check the different data set files in the Mainframe application used for data Storage",
        "impacts": [
            "replatform"
        ],
        "effort": null,
        "parents": [
            1202077
        ],
        "children": [
            1202029,
            1202042,
            1202043,
            1202051,
            1202064,
            1202065,
            1202093
        ]
    },
    {
        "name": "Oracle Database to Amazon Aurora with PostgreSQL: Syntax Remediation required",
        "id": 1202047,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Recommendations to re-platform Oracle Database to Amazon Aurora PostgreSQL that will require syntax change remediation."
        },
        "remediations": {},
        "populations": {
            "SQL": "Check if any violation for rules with TC 61045 and with tag AIP-M2C-Syntax",
            "Mainframe": "Check if any violation for rules with TC 61045 and with tag AIP-M2C-Syntax"
        },
        "description": "This rule checks unsupported syntaxes when moving from Oracle to Amazon Aurora with PostgreSQL",
        "impacts": [
            "replatform"
        ],
        "effort": "low",
        "parents": [
            1202011
        ],
        "children": [
            1106002,
            1106022,
            1106038
        ]
    },
    {
        "name": "SQL Server Database to Amazon Aurora with PostgreSQL",
        "id": 1202089,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Before migrating SQL Server Database to Postgres on AWS Aurora, follwing checks need to be manual fixed since not supported on target DB service"
        },
        "remediations": {},
        "populations": {
            "SQL": "TC 61046",
            "Mainframe": "TC 61046"
        },
        "description": "",
        "impacts": [
            "replatform"
        ],
        "effort": null,
        "parents": [
            1202094
        ],
        "children": [
            1202177,
            1202178,
            1202179
        ]
    },
    {
        "name": "Mainframe Printing and output management tools to Cloud Printing service",
        "id": 1202044,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Mainframe printing and output management tools are often specific to the mainframe environment, and may not be compatible with cloud-based systems. Identifying IBM or Independent Software Vendor printing and/or output management tools used on the z/OS environment before migration helps in determining if they need to be replaced or updated, and if planning for any necessary changes.\n\n\n"
        },
        "remediations": {},
        "populations": {},
        "description": "This rule we identify the usage of IBM or Independent Software Vendor printing or and output management too",
        "impacts": [],
        "effort": null,
        "parents": [
            1202067,
            1202077
        ],
        "children": [
            1202038,
            1202073,
            1202074
        ]
    },
    {
        "name": "SQL Server Database to Amazon Aurora with PostgreSQL: Object Type Remediation",
        "id": 1202178,
        "category": "BRANCHING-STEP",
        "rationales": {},
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": "moderate",
        "parents": [
            1202089
        ],
        "children": [
            1106142
        ]
    },
    {
        "name": "Technologies Detection",
        "id": 1202099,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "The presence of the Focus, Assembler, Easytreive, Rexx code influences the migration strategy."
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [
            1202067,
            1202077
        ],
        "children": [
            1202075,
            1202076,
            1202097,
            1202098
        ]
    },
    {
        "name": "DB2 Database to Amazon Aurora with PostgreSQL : Data Type Remediation Required",
        "id": 1202023,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Data Type is not supported by the target Database service. Automatic migration and conversion are not possible. Manual conversion with a dedicated equivalent Data Type is required."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "TC 61044 + tag Data Type Remediation"
        },
        "description": "This rule checks unsupported data types when moving from DB2 to Amazon Aurora with PostgreSQL",
        "impacts": [
            "replatform",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202005
        ],
        "children": [
            1106052,
            1106054,
            1106058,
            1106064,
            1106066,
            1106068,
            1106070
        ]
    },
    {
        "name": "Oracle Database to PostgreSQL on Amazon Aurora",
        "id": 1202011,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Before migrating Oracle Database to PostgreSQL on AWS Aurora, follwing checks need to be manual fixed since not supported on target DB service"
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [
            "replatform"
        ],
        "effort": null,
        "parents": [
            1202094
        ],
        "children": [
            1202047,
            1202175,
            1202176
        ]
    },
    {
        "name": "Oracle Database to Amazon Aurora with PostgreSQL: Object Type Remediation",
        "id": 1202176,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Recommendations to migrate your Oracle Database to PostgreSQL that will require object type remediation."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Check if any violation of rules with TC 61045 and with tag AIP-M2C-DataType"
        },
        "description": "This rule checks all unsupported used Data types",
        "impacts": [
            "replatform"
        ],
        "effort": "moderate",
        "parents": [
            1202011
        ],
        "children": [
            1202082,
            1202083,
            1106006,
            1106010,
            1106012,
            1106014,
            1106036,
            1106040,
            1106042
        ]
    },
    {
        "name": "CICS transient Data ",
        "id": 1202153,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "CICS® transient data queue services provide a generalized queueing facility. Data can be queued (stored) for subsequent internal or external processing. You can apply the following functions to selected data, specified in an application:\n\nWrite data to a transient data queue (EXEC CICS WRITEQ TD)\nRead data from a transient data queue (EXEC CICS READQ TD)\nDelete an intrapartition transient data queue (EXEC CICS DELETEQ TD)\n\n\n\n\nAs part of phasing out of the mainframe CICS transaction processing system, the Temporary Storage Queues, Temporary Data Queues are usually replaced with specific AWS services such as Amazon Kinesis Data Analytics, Amazon Simple Queue Service, or RabbitMQ for TD Queues.\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": ""
        },
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [
            1202059
        ],
        "children": [
            1202150,
            1202151
        ]
    },
    {
        "name": "Mainframe Scheduler to Cloud Scheduler",
        "id": 1202009,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "The scheduler plays a critical role in the operation of mainframe applications. If the scheduler is not compatible with the cloud environment or if the migration is not properly planned, it can cause operational disruptions, increased downtime, and loss of revenue. Knowing the used scheduler can help in assessing and mitigating risks associated with the migration\n\nDifferent schedulers have different features and capabilities. Knowing which scheduler is being used in the mainframe application can help choose an equivalent cloud native scheduler with similar functionality.\n\n\n\n\n\n"
        },
        "remediations": {},
        "populations": {},
        "description": "Identify the used Scheduler and all JCL jobs and procedures involved by this scheduler.\nIdentify Programs launched by these jobs",
        "impacts": [],
        "effort": "none",
        "parents": [
            1202067,
            1202077
        ],
        "children": [
            1202031,
            1202032,
            1202033,
            1202034
        ]
    },
    {
        "name": "SQL Server Database to Amazon Aurora with PostgreSQL: Data Type Remediation",
        "id": 1202177,
        "category": "BRANCHING-STEP",
        "rationales": {},
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": "moderate",
        "parents": [
            1202089
        ],
        "children": [
            1106114,
            1106116,
            1106118,
            1106120,
            1106122,
            1106124,
            1106126,
            1106128,
            1106130
        ]
    },
    {
        "name": "DB2 Database to Amazon Aurora with PostgretSQL: Syntax Remediation required",
        "id": 1202025,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Used Syntax is not supported by the target Database service. Automatic migration and conversion are not possible. Manual conversion with dedicated equivalent syntax is required."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "TC 61044 + tag  Syntax Remediation"
        },
        "description": "This rule checks unsupported syntaxes moving from DB2 to Amazon Aurora with PostgreSQL",
        "impacts": [
            "replatform",
            "review"
        ],
        "effort": "low",
        "parents": [
            1202005
        ],
        "children": [
            1106072,
            1106074,
            1106076,
            1106078,
            1106080,
            1106082,
            1106084,
            1106090,
            1106092,
            1106094,
            1106096,
            1106100,
            1106102,
            1106106,
            1106108
        ]
    },
    {
        "name": "Mainframe modernization with AWS",
        "id": 1202180,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "Mainframe modernization with AWS refers to the process of migrating or transforming legacy mainframe applications and workloads to the cloud-based infrastructure and services provided by Amazon Web Services (AWS)."
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [
            1202174
        ],
        "children": [
            1202067,
            1202077
        ]
    },
    {
        "name": "CICS Green Screens Multiple Access",
        "id": 1202058,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Green Screen with multiple access will be complex to review. Each program must be carefully investigated. Please, select one of the programs accessing the green screen and we will check if it is connected to the communication or data access layer."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "search for nodes with type is one of (CICS_MAP, CICS_BMS, CICS_MAPSET, CAST_CICS_MapPrototype, CAST_CICS_MapSetPrototype) "
        },
        "description": "This rule checks any CICS Map, CICS Map definition or CICS Mapset accessed by more than one program ( Monitor link)",
        "impacts": [
            "retire"
        ],
        "effort": "high",
        "parents": [
            1202059
        ],
        "children": [
            1202057,
            1202061,
            1202062
        ]
    },
    {
        "name": "IMS DB To Relation Database",
        "id": 1202084,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "IMS DB is a hierarchical database management system commonly used in mainframe environments that can be migrated to relational databases in cloud-based systems. \n\nPBS (Program Specification Block) and PCB are the control blocks used by IMS system to manage data access and processing. They are used by IMS to establish communication between a program and the IMS database.\nThey also include details such as segment names, segment lengths, segment occurrence groups, and relationships between segments. \n\nWhen Moving to AWS, IMS DB can be migrated to Amazon Relational Database Service or any x86-64 platform database engine hosted on AWS. The x86-64 platform database engine could be any of Amazon Aurora PostgreSQL, SQL Server, Oracle, DB2 LUW, or MariaDB."
        },
        "remediations": {},
        "populations": {},
        "description": "This rule allows to identify all IMS DB segements of you application, the access layers ( PSB and PC) in additional to Cobol Programs accesssing this Data base.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202077,
            1202094
        ],
        "children": [
            1202085,
            1202086,
            1202087
        ]
    },
    {
        "name": "Cobol Programs to be moved on AWS EC2 : Syntax Checks",
        "id": 1202004,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "Mainframe applications can be deployed on Aws EC2 using a Middleware Emulation. \nSome Cobol statements specific to the z/OS environment when used in a cloud environment can be error and/or security prone. So, it will be very recommended to review them and fixes issues before rehosting the Mainframe application on any Cloud Platform. \n\nIdentifying the unsupported or risky syntaxes beforehand can help organizations estimate the cost of the required code changes and/or refactoring and plan accordingly.\n\n\n\n\n"
        },
        "remediations": {},
        "populations": {},
        "description": "Identify all Cobol Statements and Synataxes that need to be reviewed before migration to the cloud",
        "impacts": [
            "rehost",
            "replatform",
            "review"
        ],
        "effort": null,
        "parents": [
            1202067
        ],
        "children": [
            1202021,
            1202022
        ]
    },
    {
        "name": "CICS Transactions",
        "id": 1202152,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "As part of phasing out of the mainframe CICS transaction processing system in favor of modern web applications, the replacement system should provide Entry points used to start a CICS transaction and run associated programs."
        },
        "remediations": {},
        "populations": {},
        "description": "",
        "impacts": [],
        "effort": null,
        "parents": [
            1202059
        ],
        "children": [
            1202148,
            1202149
        ]
    },
    {
        "name": "DB2 Database to Amazon Aurora with PostgretSQL: Object Type Remediation required",
        "id": 1202081,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Used Syntax is not supported by the target Database service. Automatic migration and conversion are not possible. Manual conversion with dedicated equivalent syntax is required."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "TC 61044 + tag  Syntax Remediation"
        },
        "description": "This rule checks unsupported object types when moving from DB2 to Amazon Aurora with PostgreSQL",
        "impacts": [
            "replatform",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202005
        ],
        "children": [
            1106104
        ]
    },
    {
        "name": "Mainframe Data Transfer Protocols to Cloud-Native File Transfer family",
        "id": 1202008,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Mainframe applications often use proprietary data transfer protocols that may not be compatible with the protocols used in the cloud environment. Identifying the protocols beforehand can help ensure that the data can be transferred smoothly and without errors.\n\nWhen moving to the cloud platform, these protocols are usually replaced with cloud-native data transfer services or protocols. Minimal Code changes or refactoring are necessary to integrate the equivalent cloud-native service.\n\n"
        },
        "remediations": {},
        "populations": {},
        "description": "Identify JCL jobs and Procedures doing data and/or file transfer \nIdentify Programs launched by these jobs",
        "impacts": [
            "rehost",
            "review",
            "replatform"
        ],
        "effort": null,
        "parents": [
            1202077
        ],
        "children": [
            1202036,
            1202039,
            1202040,
            1202041
        ]
    },
    {
        "name": "Mainframe to AWS by rehosting/replatforming your application on EC2",
        "id": 1202067,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Amazon Web Services": "Mainframe applications can be deployed on AWS EC2 using a Middleware Emulation. \nThis modernization approach via MicroFocus Replatforming involves migrating mainframe workloads to the cloud using Micro Focus technology stack. While this approach offers several benefits, it also presents some challenges and it requires a deep understanding of the legacy codebase and the ability to map mainframe functionality to modern cloud services.\n\nBefore migrating mainframe applications to the cloud, it's crucial to assess compatibility with cloud protocols and Third-Party Products/tools. Identifying communication and data transfer protocols, ensuring compatibility, and making necessary updates will ensure smooth and secure integration with the cloud environment. This evaluation helps estimate migration costs and plan effectively.\n\nData migration from mainframe systems to the cloud can be complex due to differences in data formats, storage architectures, and database technologies. Ensuring compatibility and preserving data integrity during the migration process requires careful planning.\n\nMinimal Code changes and/or refactoring are necessary to integrate with differing third-party utility interfaces, and cloud-native integration services or when modernizing the data store and data access along the way.\n"
        },
        "remediations": {},
        "populations": {},
        "description": "This rule checks all point of interest that need to be identfied and reviewed as part of a modernization project or migration to the cloud",
        "impacts": [],
        "effort": null,
        "parents": [
            1202180
        ],
        "children": [
            1202002,
            1202004,
            1202009,
            1202010,
            1202013,
            1202018,
            1202019,
            1202044,
            1202066,
            1202099
        ]
    },
    {
        "name": "CICS Green Screens Single Access",
        "id": 1202063,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Please, select the program accessing the green screen and we will check if it is connected to the communication or data access layer."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "search for nodes with type is one of (CICS_MAP, CICS_BMS, CICS_MAPSET, CAST_IMS_MessageFormatService, CAST_IMS_MessageInputDescriptor, CAST_IMS_MessageOutputDescriptor, CAST_CICS_MapPrototype, CAST_CICS_MapSetPrototype) + one callee per screen"
        },
        "description": "This rule checks any CICS Map, CICS Map definition or CICS Mapset accessed by one single program ( Monitor link)",
        "impacts": [
            "retire"
        ],
        "effort": "moderate",
        "parents": [
            1202059
        ],
        "children": [
            1202057,
            1202061,
            1202062
        ]
    },
    {
        "name": "Cobol Syntax Checks -  z/OS environment  Specific",
        "id": 1202022,
        "category": "BRANCHING-STEP",
        "rationales": {
            "Agnostic": "Some Cobol Syntax are specific to the z/OS environment and need to be reviewed before moving to Cloud Environment. if not Compilation error will be raised after the migration\n\n\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "5144: http://rulesmanager/#:-4:6h\nTo be defined in rules Manager"
        },
        "description": "Identify all Cobol Statements and Synataxes that need to be reviewed before migration to the cloud",
        "impacts": [
            "review",
            "rehost"
        ],
        "effort": "low",
        "parents": [
            1202004
        ],
        "children": [
            1202072,
            5060,
            5144
        ]
    },
    {
        "name": "Ensure DB2 Scalar Function MONTH is not used",
        "id": 1106090,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Returns the month part of the date value. The output format is integer.\nReplace DATE_PART ('MONTH', <DATE_FIELD>) with MONTH (<DATE_FIELD>)."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Function MONTH is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025,
            1202025
        ],
        "children": []
    },
    {
        "name": "Identify application's adherence to Easytreive technology",
        "id": 1202079,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "The presence of the Easytreive code influences the migration strategy. Easytreive Technology may has unique considerations during modernization, such as conversion to a higher-level language, rewriting, or reengineering. Understanding the extent of Easytreive code allows you to design an appropriate migration plan that addresses these specific requirements.\n\nFor the conversion of the code, the presence of the Easytreive technology will also guide the choice of the partner and tool as the conversion of the Easytreive is not systematically supported"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All objects of Easytreive technology  + callers & callees \nInternal types : Eztprogram OR Easymacro OR Easyfile OR Easyproc OR Easyreport"
        },
        "description": "This rule checks all Easytreive objects and the adherence to the application",
        "impacts": [
            "refactor",
            "rehost"
        ],
        "effort": "high",
        "parents": [
            1202096
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Function TIMESTAMP is not used",
        "id": 1106082,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "TIMESTAMP(<FIELD>) Converts the input into a time value, and it has to be changed to TO_TIMESTAMP (<FIELD>, <format>) in PostgreSQL.\nCURRENT TIMESTAMP has to be changed to CURRENT_TIMESTAMP."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Function TIMESTAMP is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Ensure PARTITION is not used in ALTER TABLE statements",
        "id": 1106096,
        "category": "TASK",
        "rationales": {
            "Agnostic": "AWS SCT can convert Db2 LUW tables to partitioned tables in PostgreSQL 10. There are several restrictions when converting a Db2 LUW partitioned table to PostgreSQL:\n\nYou can create a partitioned table with a nullable column in Db2 LUW, and you can specify a partition to store NULL values. However, PostgreSQL doesn’t support NULL values for RANGE partitioning.\n\nDb2 LUW can use an INCLUSIVE or EXCLUSIVE clause to set range boundary values. PostgreSQL only supports INCLUSIVE for a starting boundary and EXCLUSIVE for an ending boundary. The converted partition name is in the format <original_table_name>_<original_partition_name>.\n\nYou can create primary or unique keys for partitioned tables in Db2 LUW. PostgreSQL requires you to create primary or unique key for each partition directly. Primary or unique key constraints must be removed from the parent table. The converted key name is in the format <original_key_name>_<original_partition _name>.\n\nYou can create a foreign key constraint from and to a partitioned table in Db2 LUW. However, PostgreSQL doesn’t support foreign keys references in partitioned tables. PostgreSQL also doesn’t support foreign key references from a partitioned table to another table.\n\nYou can create an index on a partitioned table in Db2 LUW. However, PostgreSQL requires you to create an index for each partition directly. Indexes must be removed from the parent table. The converted index name is in the format <original_index_name>_<original_partition_name>.\n\nYou must define row triggers on individual partitions, not on the partitioned table. Triggers must be removed from the parent table. The converted trigger name is in the format <original_trigger_name>_<original_partition_name>."
        },
        "remediations": {
            "Agnostic": "The remediation is to remove unsupported options."
        },
        "populations": null,
        "description": "This rule will check if the following sql statements exist into DB2 SQL files:\n   ALTER TABLE ADD PARTITION\n   ALTER TABLE DETACH PARTITION\n   ALTER TABLE ATTACH PARTITION",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "LDS VSAM Files : Programs/Utilities manipulating Data",
        "id": 1202043,
        "category": "TASK",
        "rationales": {
            "Azure": "LDS stands for Linear Data Set, which is another type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. Unlike KSDS VSAM files that store data in a sequential order based on a key field, LDS VSAM files store data in a linear, non-sequential order.\n\nIn LDS VSAM files, each record is assigned a Relative Byte Address (RBA) that indicates its position in the file. Records can be accessed sequentially by reading the file in order, or randomly by specifying the RBA of the desired record.\n\nLDS VSAM files are particularly useful for storing large amounts of data that are frequently updated or appended, as they provide fast access to individual records without having to scan the entire file. However, they are not as efficient for applications that require frequent searches based on key values.\n\nWhen moving to Azure Cloud, VSAM files are, usually, replicated to Azure SQL Database \n\nVSAM has also many characteristics of a NO-SQL database and than can be moved to Cosmos DB \nhttps://azure.microsoft.com/mediahandler/files/resourcefiles/vsam-to-azure-cosmos-db/VSAM%20to%20Azure%20Cosmos%20DB.pdf) ",
            "Amazon Web Services": "LDS stands for Linear Data Set, which is another type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. Unlike KSDS VSAM files that store data in a sequential order based on a key field, LDS VSAM files store data in a linear, non-sequential order.\n\nIn LDS VSAM files, each record is assigned a Relative Byte Address (RBA) that indicates its position in the file. Records can be accessed sequentially by reading the file in order, or randomly by specifying the RBA of the desired record.\n\nLDS VSAM files are particularly useful for storing large amounts of data that are frequently updated or appended, as they provide fast access to individual records without having to scan the entire file. However, they are not as efficient for applications that require frequent searches based on key values.\n\n\nWhen moving to AWS, VSAM files are, usually, replicated to Amazon RDS\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/migrate-and-replicate-vsam-files-to-amazon-rds-or-amazon-msk-using-connect-from-precisely.html\n\n",
            "Gougle Cloud Platform": "LDS stands for Linear Data Set, which is another type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. Unlike KSDS VSAM files that store data in a sequential order based on a key field, LDS VSAM files store data in a linear, non-sequential order.\n\nIn LDS VSAM files, each record is assigned a Relative Byte Address (RBA) that indicates its position in the file. Records can be accessed sequentially by reading the file in order, or randomly by specifying the RBA of the desired record.\n\nLDS VSAM files are particularly useful for storing large amounts of data that are frequently updated or appended, as they provide fast access to individual records without having to scan the entire file. However, they are not as efficient for applications that require frequent searches based on key values."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "(EXISTS {MATCH (o:Object)-[:Property {value:'LDS VSAM File'}]->(op:ObjectProperty)WHERE op.Id IN ['141023']})\n\nFor each LDS VSAM dataset called by Cobol Program: LDS VSAM dataset + Calling Program + ACCESS MODE\nFor each LDS VSAM dataset called by Any Utility: LDS VSAM dataset + Calling Any Utility + ACCESS MODE"
        },
        "description": "Listing CRUD (Create, Read, Update, Delete) operations is important to migrate LDS VSAM files to the cloud because it helps to identify the specific operations that the application performs on the data stored in the VSAM files. \nThis information is critical in determining the appropriate cloud storage solution and configuring it to provide the necessary performance and reliability.\n\n\n\nFor each ESDS VSAM dataset called by Cobol Program: LDS VSAM dataset + Calling Program + ACCESS MODE\nFor each ESDS VSAM dataset called by Any Utility: LDS VSAM dataset + Calling Any Utility + ACCESS MODE",
        "impacts": [
            "replatform"
        ],
        "effort": "high",
        "parents": [
            1202006
        ],
        "children": []
    },
    {
        "name": "JCL Job/Cobol Program using 3rd Party Products/tools : StreamWeaver (ISV BMC)",
        "id": 1202038,
        "category": "TASK",
        "rationales": {
            "Azure": "StreamWeaver (ISV BMC) printing tool can be replaced by a cloud-native solution\nAll JCL/programs using this tool need to be identified to consider adoption and deployment with new cloud service/solution",
            "Amazon Web Services": "StreamWeaver (ISV BMC) printing tool can be replaced by a cloud-native solution as LRS printing solution on AWS.\nAll JCL/programs using this tool need to be identified to consider adoption and deployment with new cloud service/solution",
            "Gougle Cloud Platform": "StreamWeaver (ISV BMC) printing tool can be replaced by a cloud-native solution\nAll JCL/programs using this tool need to be identified to consider adoption and deployment with new cloud service/solution"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "JCL Job/Procedure calling 'StreamWeaver' utilities + Cobol program called by this JCL Job/Procedure\nStream Weaver Utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20StreamWeaver"
        },
        "description": "Identify JCL Jobs and JCL Procedures calling StreamWeaver Utilities\nIdentify Programs launched by these jobs",
        "impacts": [
            "replatform",
            "review",
            "refactor"
        ],
        "effort": "moderate",
        "parents": [
            1202044
        ],
        "children": []
    },
    {
        "name": "Cobol Programs candidate for AWS Lambda function conversion: Data-dependent Programs",
        "id": 1202001,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Check all programs accessing Data Objects : Any DB (IMS, DB2, ORACLE...) objects  or Data File Object ( VSAM, GSAM, PDS, CICS, GDG DataSet)\n\n\nData-dependent programs accessing SHARED data file/DB table"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "CAST_COBOL_SavedProgram with the property 'Number of Transaction' = 1\nThe Entry Point of the transaction should have the property 'Number of Transaction' = 1\n\n\n\nThe program is accessing a SHARED Database table or SHARED DataSet File Storage\nA SHARED Database table or SHARED DataSet File Storage: means that the table or NOT the DataSet File Storage is accessed MORE THEN the Program  \n "
        },
        "description": "Among the candidates for AWS Lambda function conversion, This rule identifies the program accessing the SHARED Database table or Any DataSet file Storage",
        "impacts": [],
        "effort": null,
        "parents": [
            1202002
        ],
        "children": []
    },
    {
        "name": "Ensure DECLARE cursor is not used",
        "id": 1106100,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Cursor operations SQL statements used in stored procedures, functions and triggers from IBM DB2 to PostgreSQL should be Converted as follows: \n\n1-Cursor declaration: DECLARE cur CURSOR FOR query  To be Replaced by  cur CURSOR FOR query\n2-Return result set DECLARE cur CURSOR WITH RETURN  To be Replaced by cur REFCURSOR\n3-Dynamic cursors: DECLARE cur WITH RETURN FOR stmt PREPARE stmt FROM 'query_string'  To be Replaced by  OPEN cur FOR EXECUTE 'query_string'"
        },
        "populations": null,
        "description": "This rule checks Cursor operations 'DECLARE cur' Statements in SQL DB2 files and Embedded SQL Queries.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Ensure SQL server Scalar Function CONVERT is not used",
        "id": 1106132,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from SQL serevr to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Convert to integer\n\nScalar Function CONVERT(BIGINT, exp) in SQL server should be replaced by CAST(exp AS BIGINT) in PostgreSQL.\nScalar Function CONVERT(INT | INTEGER, exp in SQL server should be replaced by CAST(exp AS INT | INTEGER) in PostgreSQL.\nScalar Function CONVERT(SMALLINT, exp) in SQL server should be replaced by CAST(exp AS SMALLINT) in PostgreSQL.\nScalar Function CONVERT(TINYINT, exp) in SQL server should be replaced by CAST(exp AS SMALLINT) in PostgreSQL.\n\nConvert to number \nScalar Function CONVERT(NUMERIC(p,s), exp) in SQL server should be replaced by CAST(exp AS NUMERIC(p,s)) in PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the usage of CONVERT Scalar Function in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179
        ],
        "children": []
    },
    {
        "name": "Identify application's adherence to Rexx technology",
        "id": 1202097,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "The presence of the Rexx code influences the migration strategy. Rexx Technology may has unique considerations during modernization, such as conversion to a higher-level language, rewriting, or reengineering. Understanding the extent of Easytreive code allows you to design an appropriate migration plan that addresses these specific requirements.\n\nFor the conversion of the code, the presence of the Rexx technology will also guide the choice of the partner and tool as the conversion of Rexx is not systematically supported"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All objects of Rexx technology  + callers & callees \nInternal types : Rexxprogram OR Rexxfile OR Rexxfunction OR Rexxprocedure OR Unknown_Rexxprogram"
        },
        "description": "This rule checks all Rexx objects and the adherence to the application",
        "impacts": [
            "refactor",
            "rehost"
        ],
        "effort": "high",
        "parents": [
            1202099
        ],
        "children": []
    },
    {
        "name": "Identify application's adherence to Focus technology",
        "id": 1202095,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "The presence of the Focus code influences the migration strategy. Focus Technology may has unique considerations during modernization, such as conversion to a higher-level language, rewriting, or reengineering. Understanding the extent of Focus code allows you to design an appropriate migration plan that addresses these specific requirements.\n\nFor the conversion of the code, the presence of the Focus technology will also guide the choice of the partner and tool as the conversion of Focus is not systematically supported"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All objects of Focus technology  + callers & callees \nInternal types : FOCUSTable OR FOCUSTablef OR FOCUSDefine OR FOCUSMatch OR FOCUSGraph OR FOCUSJoin OR FOCUSMaster OR FOCUSprocedure"
        },
        "description": "This rule checks all Focus objects and the adherence to the application",
        "impacts": [
            "refactor",
            "rehost"
        ],
        "effort": "high",
        "parents": [
            1202096
        ],
        "children": []
    },
    {
        "name": "PDS Files: Programs/Utilities manipulating Data",
        "id": 1202014,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Please review each Cobol Program reading/writing in PDS Dataset in order to plan replacement using SQL statements."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "(EXISTS {MATCH (o:Object)-[:Property {value:'PDS Dataset'}]->(op:ObjectProperty)WHERE op.Id IN ['141023']})\n\nFor each PDS dataset called by Cobol Program: PDS dataset + Calling Program + ACCESS MODE\nFor each PDS dataset called by Any Utility: PDS dataset + Calling Any Utility + ACCESS MODE\n"
        },
        "description": "For Each used PDS Dataset, we display the access mode(s) (Read/Write mode) and Calling Cobol Program or Utility",
        "impacts": [],
        "effort": "low",
        "parents": [
            1202013
        ],
        "children": []
    },
    {
        "name": "Ensure SQL Server SET/SELECT variable is not used",
        "id": 1106144,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from SQL Server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "Variable assignments statements used in DML files, stored procedures, functions and triggers should be converted before re-platforming your SQL Server Database to PostgreSQL:\n\nSET @var = expression should be replaced with var := expression\nSET @var = (SELECT expression FROM …) should be replaced with var := (SELECT expression FROM …)\nSELECT @var = exp, @var2 = exp2 FROM … should be replaced with SELECT exp, exp2 INTO var, var2 FROM …."
        },
        "populations": null,
        "description": "This rule checks the variable assignment in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure VARBINARY data type is not used",
        "id": 1106114,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace VARBINARY(n) data type with BYTEA data type\nReplace VARBINARY(max) data type with BYTEA data type"
        },
        "populations": null,
        "description": "This rule checks if any VARBINARY data type is used in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "Ensure SMALLMONEY data type is not used",
        "id": 1106120,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace SMALLMONEY data type with MONEY data type"
        },
        "populations": null,
        "description": "This rule checks if any SMALLMONEY data type is used in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "Unknown Transient Data ",
        "id": 1202151,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Cobol Program accessing CICS transient Data Queue service should be identified. These programs will require change/review of the connection APIs with the new cloud messaging service "
        },
        "remediations": {},
        "populations": {
            "Mainframe": "CAST_CICS_TDQueuePrototype and calling Program"
        },
        "description": "This rule identifies Unknown CICS Transient Data",
        "impacts": [],
        "effort": null,
        "parents": [
            1202153
        ],
        "children": []
    },
    {
        "name": "Cobol Program accessing IMS Segement",
        "id": 1202085,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying IMS segments, their access mode and eventually their relationships can help understanding the design of the appropriate relational database schema.\n\nCobol programs that access IMS DB will need to be modified to interact with the new relational database. By identifying the programs and their dependencies on IMS DB, you can plan and implement the necessary changes in the application code, such as updating SQL queries or data access logic."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "IMS Segment (InternalType OR CAST_IMS_AnalyzedSegment)\nFor Each Segment, provides the PCB calling  (InternalType: CAST_IMS_DatabaseProgramControlBlock) + Calling Cobol Program\n\n"
        },
        "description": "This rule identifies the IMS Segments used in the application and Progams accessing these segments via PCB/PSB",
        "impacts": [],
        "effort": "high",
        "parents": [
            1202084
        ],
        "children": []
    },
    {
        "name": "Avoid DISPLAY ... UPON CONSOLE",
        "id": 5072,
        "category": "TASK",
        "rationales": {
            "Agnostic": "The DISPLAY statement used with the UPON CONSOLE addition sends information to the console and then, it requires operator responses."
        },
        "remediations": {
            "Agnostic": "Only use the DISPLAY statement for debug purpose and do not send information to the console. In the indicator area, use the 'D' character to specify that the statement is for debug version of the program. The DISPLAY statement should only be used to designate the start of the batch program, or the result of the execution of the batch program."
        },
        "populations": null,
        "description": "This rule searches for COBOL programs using the DISPLAY statements with the \"UPON CONSOLE\" addition.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202021
        ],
        "children": []
    },
    {
        "name": "Identify application's adherence to Rexx technology",
        "id": 1202080,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "The presence of the Rexx code influences the migration strategy. Rexx Technology may has unique considerations during modernization, such as conversion to a higher-level language, rewriting, or reengineering. Understanding the extent of Easytreive code allows you to design an appropriate migration plan that addresses these specific requirements.\n\nFor the conversion of the code, the presence of the Rexx technology will also guide the choice of the partner and tool as the conversion of Rexx is not systematically supported"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All objects of Rexx technology  + callers & callees \nInternal types : Rexxprogram OR Rexxfile OR Rexxfunction OR Rexxprocedure OR Unknown_Rexxprogram"
        },
        "description": "This rule checks all Rexx objects and the adherence to the application",
        "impacts": [
            "refactor",
            "rehost"
        ],
        "effort": "high",
        "parents": [
            1202096
        ],
        "children": []
    },
    {
        "name": "[CLONE] JCL Job/Cobol Program using 3rd Party Products/tools : CA-Spool",
        "id": 1202074,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "CA-SPOOL(Formerly known as SAR), a SYSOUT Archival and Retrieval system, is a facility for storing and retrieving computer output.\nIt can be replaced by a cloud-native solution as LRS printing solution on AWS.\nAll JCL/programs using this tool need to be identified to consider adoption and deployment with new cloud service/solution"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "JCL Job/Procedure calling 'StreamWeaver' utilities + Cobol program called by this JCL Job/Procedure\nStream Weaver Utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20StreamWeaver"
        },
        "description": "",
        "impacts": [
            "replatform",
            "review"
        ],
        "effort": "high",
        "parents": [
            1202044
        ],
        "children": []
    },
    {
        "name": "JCL Job/ JCL Procedure using Control M Scheduler (ISV BMC)",
        "id": 1202032,
        "category": "TASK",
        "rationales": {
            "Azure": "BMC provides specific workflow orchestration for Control-M used for mainframe applications on Azure VM or with other Azure services \n\nMore details can be found here: \nhttps://www.bmc.com/it-solutions/control-m-integrations/azure-vm-for-control-m.html\nhttps://docs.bmc.com/docs/ctm_integrations/control-m-for-azure-functions-1066864662.html\n...\n\n\nIdentifying all JCL jobs, JCL procedures, and eventually Cobol Programs handled and monitored by Control-M scheduler allows the migration team to assess the scope and complexity of the scheduling/workflow automation \ninfrastructure changes required to migrate to the cloud environment.",
            "Amazon Web Services": "Control-M is a BMC tool for workflow orchestration on-premises or as a service. It's used to build, define, schedule, manage, and monitor production workflows, ensuring visibility, reliability, and improving SLAs.\n\nBMC provides specific workflow orchestration for Control-M used for mainframe applications on AWS cloud environment. \nThis workflow integrates some AWS native services: For data processing, Amazon EMR is used because it gives access to a wide variety of tools in the Apache Hadoop ecosystem for big data processing and analytics….  \nMore details can be found here: https://aws.amazon.com/blogs/apn/how-to-orchestrate-a-data-pipeline-on-aws-with-control-m-from-bmc-software/\n\n\nIdentifying all JCL jobs, JCL procedures, and eventually Cobol Programs handled and monitored by Control-M scheduler allows the migration team to assess the scope and complexity of the scheduling/workflow automation \ninfrastructure changes required to migrate to the cloud environment.",
            "Gougle Cloud Platform": "Control-M is a BMC tool for workflow orchestration on-premises or as a service. It's used to build, define, schedule, manage, and monitor production workflows, ensuring visibility, reliability, and improving SLAs.\n\n\nThe Google VM provides a plugin for Control-M to enable the integration of Google VM jobs with existing Control-M workflows. \n\n\nMore details can be found here: \nhttps://www.bmc.com/it-solutions/control-m-integrations/gcp-vm.html\nhttps://docs.bmc.com/docs/ctm_integrations/control-m-for-google-virtual-machine-1125418845.html\nhttps://docs.bmc.com/docs/ctm_integrations/control-m-for-google-batch-1197120468.html\n\n\nIdentifying all JCL jobs, JCL procedures, and eventually Cobol Programs handled and monitored by Control-M scheduler allows the migration team to assess the scope and complexity of the scheduling/workflow automation \ninfrastructure changes required to migrate to the cloud environment.\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Control M Utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=like%20%25Control%25M%25\nJCL Job/Procedure calling 'Control M' utilities + Cobol program called by this JCL Job/Procedure"
        },
        "description": "Identify all JCL Jobs and JCL Procedures calling Control-M Scheduler utilities\nIdentify Programs launched by these jobs",
        "impacts": [
            "rehost",
            "replatform",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202009
        ],
        "children": []
    },
    {
        "name": "Cobol Program using CICS Transaction Gateway (CTG)",
        "id": 1202019,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying communication protocols for mainframe applications is an important step in the cloud migration process because it helps ensure that the application can continue to communicate effectively with other systems and applications once it is moved to the cloud.\n\nBy identifying the communication protocols used by the mainframe application, you can assess whether they are compatible with the cloud environment and determine if any replication with equivalent cloud-native services or any updates are needed to ensure smooth communication between the mainframe application and other systems in the cloud.\n\nCTG (CICS Transaction Gateway) provides resource adapters to connect Java client programs to existing CICS programs in a CICS server. CICS programs using this communication protocol should be identified before migration "
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Cobol Program calling CTG utilities\nhttp://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20CTG"
        },
        "description": "Identify all Cobol Programs using CTG communication protocol.",
        "impacts": [
            "rehost",
            "replatform",
            "review",
            "refactor"
        ],
        "effort": "low",
        "parents": [
            1202067,
            1202077
        ],
        "children": []
    },
    {
        "name": "Cobol Program using CICS Transient data",
        "id": 1202150,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Cobol Program accessing CICS transient Data Queue service should be identified. These programs will require change/review of the connection APIs with the new cloud messaging service "
        },
        "remediations": {},
        "populations": {
            "Mainframe": "CAST_CICS_TDQueue and calling Program "
        },
        "description": "This rule identifies COBOL programs Calling CICS Transient Data",
        "impacts": [
            "retire",
            "review"
        ],
        "effort": "low",
        "parents": [
            1202153
        ],
        "children": []
    },
    {
        "name": "Ensure SQL server Scalar Function DATEDIFF is not used",
        "id": 1106136,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from SQL serevr to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Scalar Function DATEDIFF in SQL server should be replaced interval expression."
        },
        "populations": null,
        "description": "This rule checks the usage of DATEDIFF Scalar Function in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure PL/SQL package DBMS_SCHEDULER is not used",
        "id": 1202082,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "Aurora PostgreSQL can be combined with Amazon CloudWatch and Lambda to get similar functionality,"
        },
        "remediations": {},
        "populations": {
            "SQL": "http://rulesmanager/#:1n:2n0",
            "Mainframe": "http://rulesmanager/#:1n:2n0"
        },
        "description": "cf- description : http://rulesmanager/#:1n:2n0",
        "impacts": [],
        "effort": "moderate",
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "Cobol Programs candidate for AWS Lambda function conversion: Data-independent programs",
        "id": 1202027,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Data-independent programs: Cobol Programs accessing NOT SHRAED DB table/Data file are good candidate for aws Lambda conversion"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "CAST_COBOL_SavedProgram with the property 'Number of Transaction' = 1\nThe Entry Point of the transaction should have the property 'Number of Transaction' = 1\n\nThe program is accessing a NOT SHARED Database table or NOT Shared DataSet File Storage\nNOT SHARED Database table or NOT SHARED DataSet File Storage: means that the table or NOT the DataSet File Storage is accessed only by this program \n\n\n"
        },
        "description": "Among the candidates for AWS Lambda function conversion, This rule identifies the program accessing NOT Shared Database table or Any DataSet file Storage",
        "impacts": [
            "replatform"
        ],
        "effort": "low",
        "parents": [
            1202002
        ],
        "children": []
    },
    {
        "name": "Ensure LOB data types are not used",
        "id": 1106020,
        "category": "TASK",
        "rationales": {
            "Agnostic": "LOB storage is not supported by PostgreSQL."
        },
        "remediations": {
            "Agnostic": "Replace Oracle LOB data types with the following PostgreSQL data types:\n- BFILE can be replaced with VARCHAR(255) or CHARACTER VARYING(255)\n- BLOB can be replaced with BYTEA\n- CLOB and NCLOB can be replaced with TEXT"
        },
        "populations": null,
        "description": "This rule checks the usage of LOB Storage in Oracle Database(s) and the explicit conversion functions TO_CLOB and TO_NCLOB which convert other data types to LOB data types.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202175
        ],
        "children": []
    },
    {
        "name": "Identify application's adherence to Assembler technology",
        "id": 1202075,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "When deploying Mainframe application on Aws EC2 using a Microfocus, note that Assembler executables do not run in production environments.\n\nThe product contains a command line version of MFASM, the mainframe assembler emulator for IBM High Level Assembler programs allows users to create assembler executables or data tables within the Visual Studio environment. \nThe MFASM component is an early adopter release intended to provide a test environment for COBOL applications to call needed assembler subroutines which have already been developed and debugged in other environments. This test environment is for Enterprise Developer only and does not include a debug facility for Assembler. Assembler executables do not run in production environments."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All objects of Assembler technology  + callers & callees \nInternal types : ASMZOSProgram ( ID= 2043005) OR ASM_MACRO (ID=2043007) OR CallTo_program (ID=\"2043006)"
        },
        "description": "This rule checks all assembler objects and the adherence of the application",
        "impacts": [
            "refactor",
            "rehost"
        ],
        "effort": "high",
        "parents": [
            1202099
        ],
        "children": []
    },
    {
        "name": "VSAM files defined but not used",
        "id": 1202065,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying defined Datased that are not used for data Storage is useful to optimize migration effort and cost. \nThese datasets may be the symptom of Dead Code and so good candidates to be retired\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "VSAM dataset Called by Cobol Program with DEFINE link ONLY\nVSAM dataset called ONLY by JCL Steps"
        },
        "description": "This rule checks VSAM datasets defined but not used for data storage.",
        "impacts": [
            "refactor",
            "replatform"
        ],
        "effort": "low",
        "parents": [
            1202006
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Functions DECIMAL/DEC are not used",
        "id": 1106094,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "DECIMAL/DEC converts either character or numeric input to decimal. PostgreSQL has no direct equivalent, you should use TO_NUMBER instead."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Functions DECIMAL/DEC are used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Ensure FROM keyword is used in DELETE Statement",
        "id": 1106112,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error."
        },
        "remediations": {
            "Agnostic": "FROM keyword is required for DELETE FROM tab"
        },
        "populations": null,
        "description": "This rule checks if FROM keyword is used in DELETE Statement.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179,
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure TIMESTAMP data type is not used",
        "id": 1106118,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace TIMESTAMP data type with BYTEA data type"
        },
        "populations": null,
        "description": "This rule checks if any TIMESTAMP data type is used in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "Ensure SYSIBM.SYSDUMMY1 table is not used",
        "id": 1106104,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "There is no “SYSIBM.SYSDUMMY1” table in PostgreSQL. PostgreSQL allows a “SELECT” without ”FROM” clause. You can remove this by using script."
        },
        "populations": null,
        "description": "This rule checks if SYSIBM.SYSDUMMY1 table is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202081
        ],
        "children": []
    },
    {
        "name": "Identify application's adherence to Easytreive technology",
        "id": 1202076,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "Easytreive is supported by MicroFocus Contact your Micro Focus SupportLine representative for more details \nhttps://www.microfocus.com/documentation/enterprise-developer/ed30/Upgrading_to_ED_for_VS_30.pdf"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All objects of Easytreive technology  + callers & callees \nInternal types : Eztprogram OR Easymacro OR Easyfile OR Easyproc OR Easyreport"
        },
        "description": "This rule checks all Easytreive objects and the adherence to the application",
        "impacts": [
            "refactor",
            "rehost"
        ],
        "effort": "high",
        "parents": [
            1202099
        ],
        "children": []
    },
    {
        "name": "JCL Job/Cobol Program  using 3rd Party Products/tools : CA-ACF2 (ISV Broadcom)",
        "id": 1202035,
        "category": "TASK",
        "rationales": {
            "Agnostic": "CA-ACF2 (ISV Broadcom) is a Security and Access Control Tool for mainframe applications on the z/OS environment. During application migration to the cloud, this tool will be likely mapped to an equivalent native cloud Service. AWS Identity and Access Management (IAM) can be an Alternative service and AWS ( AD Azure). All JCL jobs/Procedures and eventually Cobol program using this tool should identified since specific integration with Cloud service will be required."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "CA-ACF2 utilities: http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=like%20%25CA%25ACF2%25%20\nJCL Job/Procedure calling CA-ACF2 utilities + Cobol program called by this JCL Job/Procedure"
        },
        "description": "",
        "impacts": [
            "rehost",
            "replatform",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202010
        ],
        "children": []
    },
    {
        "name": "RRDS VSAM Files: Programs/Utilities manipulating Data",
        "id": 1202051,
        "category": "TASK",
        "rationales": {
            "Azure": "RRDS stands for Relative Record Data Set, which is another type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. RRDS VSAM files are used to store data in fixed-length records that can be accessed randomly based on a relative record number (RRN).\n\nIn RRDS VSAM files, each record is assigned a unique RRN that indicates its position in the file. Records can be accessed directly by specifying the RRN of the desired record, which makes RRDS VSAM files particularly useful for applications that require fast random access to individual records.\n\nUnlike KSDS and LDS VSAM files, RRDS VSAM files store records of fixed length, which can be efficient for certain types of data such as binary data. However, RRDS files may not be optimal for applications that store variable-length records or require frequent updates.\n\n\nWhen moving to Azure Cloud, VSAM files are, usually, replicated to Azure SQL Database \n\nVSAM has also many characteristics of a NO-SQL database and than can be moved to Cosmos DB \nhttps://azure.microsoft.com/mediahandler/files/resourcefiles/vsam-to-azure-cosmos-db/VSAM%20to%20Azure%20Cosmos%20DB.pdf) ",
            "Amazon Web Services": "RRDS stands for Relative Record Data Set, which is another type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. RRDS VSAM files are used to store data in fixed-length records that can be accessed randomly based on a relative record number (RRN).\n\nIn RRDS VSAM files, each record is assigned a unique RRN that indicates its position in the file. Records can be accessed directly by specifying the RRN of the desired record, which makes RRDS VSAM files particularly useful for applications that require fast random access to individual records.\n\nUnlike KSDS and LDS VSAM files, RRDS VSAM files store records of fixed length, which can be efficient for certain types of data such as binary data. However, RRDS files may not be optimal for applications that store variable-length records or require frequent updates.\n\nWhen moving to AWS, VSAM files are, usually, replicated to Amazon RDS\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/migrate-and-replicate-vsam-files-to-amazon-rds-or-amazon-msk-using-connect-from-precisely.html",
            "Gougle Cloud Platform": "RRDS stands for Relative Record Data Set, which is another type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. RRDS VSAM files are used to store data in fixed-length records that can be accessed randomly based on a relative record number (RRN).\n\nIn RRDS VSAM files, each record is assigned a unique RRN that indicates its position in the file. Records can be accessed directly by specifying the RRN of the desired record, which makes RRDS VSAM files particularly useful for applications that require fast random access to individual records.\n\nUnlike KSDS and LDS VSAM files, RRDS VSAM files store records of fixed length, which can be efficient for certain types of data such as binary data. However, RRDS files may not be optimal for applications that store variable-length records or require frequent updates."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "(EXISTS {MATCH (o:Object)-[:Property {value:'RRDS VSAM File'}]->(op:ObjectProperty)WHERE op.Id IN ['141023']})\n\nFor each RRDS VSAM dataset called by Cobol Program: LDS VSAM dataset + Calling Program + ACCESS MODE\nFor each RRDS VSAM dataset called by Any Utility: LDS VSAM dataset + Calling Any Utility + ACCESS MODE"
        },
        "description": "Listing CRUD (Create, Read, Update, Delete) operations is important to migrate RRDS VSAM files to the cloud because it helps to identify the specific operations that the application performs on the data stored in the VSAM files. \nThis information is critical in determining the appropriate cloud storage solution and configuring it to provide the necessary performance and reliability.\n\n\nFor each ESDS VSAM dataset called by Cobol Program: RRDS VSAM dataset + Calling Program + ACCESS MODE\nFor each ESDS VSAM dataset called by Any Utility: RRDS VSAM dataset + Calling Any Utility + ACCESS MODE",
        "impacts": [
            "replatform"
        ],
        "effort": "high",
        "parents": [
            1202006
        ],
        "children": []
    },
    {
        "name": "Ensure PL/SQL package DBMS_RANDOM is not used",
        "id": 1106010,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Oracle’s DBMS_RANDOM package provides functionality for generating random numbers or strings as part of an SQL statement or PL/SQL procedure. PostgreSQL does not provide a dedicated package equivalent to Oracle DBMS_RANDOM : Migration is not possible. However, other PostgreSQL functions can be used as workarounds under certain conditions."
        },
        "remediations": {
            "Agnostic": "PostgreSQL: Generating random numbers can be performed using the random() function. \nFor generating random strings, you can use the value returned from the random() function coupled with an md5() function."
        },
        "populations": null,
        "description": "This rule checks the usage of the DBMS_RANDOM package in the Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "Cobol Program using Advanced Program To Program Communication ( APPC) Protocol",
        "id": 1202018,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying communication protocols for mainframe applications is an important step in the cloud migration process because it helps ensure that the application can continue to communicate effectively with other systems and applications once it is moved to the cloud.\n\nBy identifying the communication protocols used by the mainframe application, you can assess whether they are compatible with the cloud environment and determine if any replication with equivalent cloud-native services or any updates are needed to ensure smooth communication between the mainframe application and other systems in the cloud.\n\nAPPC (Advanced Program-to-Program Communications protocol, also known as LU 6.2, was introduced by IBM in 1982) is used to address the exchange of data between two peer programs that are located either in the same computer or in two systems connected by the network of the z/OS operating system. \n\n\n\n\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "APPC utilities: http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20APPC\nCobol Program calling APPC utilities"
        },
        "description": "Identify all Cobol Programs using APPC communication protocol.",
        "impacts": [
            "rehost",
            "replatform",
            "review"
        ],
        "effort": "low",
        "parents": [
            1202067,
            1202077
        ],
        "children": []
    },
    {
        "name": "ESDS VSAM Files: Programs/Utilities manipulating Data",
        "id": 1202029,
        "category": "TASK",
        "rationales": {
            "Azure": "ESDS VSAM data sets files are used to store data in sequential order, similar to KSDS VSAM data sets files, but they do not have a key field to uniquely identify each record.\n\nIn ESDS VSAM files, records are stored in the order in which they are written to the file, and each record is assigned a relative byte address (RBA) that indicates its position in the file. \nRecords can be accessed sequentially by reading the file in order, but random access to individual records is not efficient.\n\nESDS VSAM files are particularly useful for applications that require high-speed data transfer and bulk data processing, such as batch processing jobs. They are also efficient for storing large amounts of data that are frequently updated or appended, as new records are simply added to the end of the file.\n\n\nWhen moving to Azure Cloud, VSAM files are, usually, replicated to Azure SQL Database \n\nVSAM has also many characteristics of a NO-SQL database and than can be moved to Cosmos DB \nhttps://azure.microsoft.com/mediahandler/files/resourcefiles/vsam-to-azure-cosmos-db/VSAM%20to%20Azure%20Cosmos%20DB.pdf) ",
            "Amazon Web Services": "ESDS VSAM data sets files are used to store data in sequential order, similar to KSDS VSAM data sets files, but they do not have a key field to uniquely identify each record.\n\nIn ESDS VSAM files, records are stored in the order in which they are written to the file, and each record is assigned a relative byte address (RBA) that indicates its position in the file. \nRecords can be accessed sequentially by reading the file in order, but random access to individual records is not efficient.\n\nESDS VSAM files are particularly useful for applications that require high-speed data transfer and bulk data processing, such as batch processing jobs. They are also efficient for storing large amounts of data that are frequently updated or appended, as new records are simply added to the end of the file.\n\n\nWhen moving to AWS, VSAM files are, usually, replicated to Amazon RDS\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/migrate-and-replicate-vsam-files-to-amazon-rds-or-amazon-msk-using-connect-from-precisely.html\n\n\n",
            "Gougle Cloud Platform": "ESDS VSAM data sets files are used to store data in sequential order, similar to KSDS VSAM data sets files, but they do not have a key field to uniquely identify each record.\n\nIn ESDS VSAM files, records are stored in the order in which they are written to the file, and each record is assigned a relative byte address (RBA) that indicates its position in the file. \nRecords can be accessed sequentially by reading the file in order, but random access to individual records is not efficient.\n\nESDS VSAM files are particularly useful for applications that require high-speed data transfer and bulk data processing, such as batch processing jobs. They are also efficient for storing large amounts of data that are frequently updated or appended, as new records are simply added to the end of the file."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "List ESDS VSAM Files (EXISTS {MATCH (o:Object)-[:Property {value:'ESDS VSAM File'}]->(op:ObjectProperty)WHERE op.Id IN ['141023']})\n\nFor each ESDS VSAM dataset called by Cobol Program: ESDS VSAM dataset + Calling Program + ACCESS MODE\nFor each ESDS VSAM dataset called by Any Utility: ESDS VSAM dataset + Calling Any Utility + ACCESS MODE\n"
        },
        "description": "Listing different access modes is important to migrate ESDS VSAM files to the cloud because it helps to identify the specific operations that the application performs on the data stored in the VSAM files. \n\nThis information is critical in determining the appropriate cloud storage solution and configuring it to provide the necessary performance and reliability.\n\nThis rule lists of all Cobol Programs and utilities accessing ESDS VSAM files and access modes",
        "impacts": [
            "replatform"
        ],
        "effort": "high",
        "parents": [
            1202006
        ],
        "children": []
    },
    {
        "name": "JCL Job/JCL Procedure doing data Data Transfer with Co:Z SFTP Protocol",
        "id": 1202041,
        "category": "TASK",
        "rationales": {
            "Azure": "Co:Z SFTP is a file transfer protocol used to transfer files between two systems over a network. It is a proprietary protocol developed by IBM for use with their Co:Z toolkit.\n\nWhen moving mainframe applications using Co:Z SFTP protocol, many changes and modifications will be required to replace it by equivalent native cloud transfer services/protocols.\n\nIdentifying the protocol beforehand and all JCL jobs and programs involved can help to assess the complexity of the Integration of data transfer services/protocols on the target cloud environment.\n",
            "Amazon Web Services": "Co:Z SFTP is a file transfer protocol used to transfer files between two systems over a network. It is a proprietary protocol developed by IBM for use with their Co:Z toolkit.\n\nWhen moving mainframe applications using Co:Z SFTP protocol, many changes and modifications will be required to replace it by an equivalent native cloud transfer services/protoles \n\n\nAWS Transfer Family service enables users to securely scale file transfers to Amazon S3 and Amazon EFS using SFTP, FTPS, and FTP protocols. Integration of this service will require minimum code change for all JCL Jobs/Procedures using NDM Protocol.\n\nIdentifying the protocol beforehand and all JCL jobs and programs involved can help to assess the complexity of the Integration of data transfer services/protocols on the target cloud environment.\n",
            "Gougle Cloud Platform": "Co:Z SFTP is a file transfer protocol used to transfer files between two systems over a network. It is a proprietary protocol developed by IBM for use with their Co:Z toolkit.\n\nWhen moving mainframe applications using Co:Z SFTP protocol, many changes and modifications will be required to replace it by equivalent native cloud transfer services/protocols.\n\nIdentifying the protocol beforehand and all JCL jobs and programs involved can help to assess the complexity of the Integration of data transfer services/protocols on the target cloud environment.\n\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Co:Z SFTP utilities: http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20SFTP\nJCL Job/JCL Procedure calling Co:Z SFTP utilities"
        },
        "description": "Identify JCL Jobs and JCL Procedure calling Co:Z SFTP utilities",
        "impacts": [
            "rehost",
            "review",
            "replatform",
            "refactor"
        ],
        "effort": "moderate",
        "parents": [
            1202008
        ],
        "children": []
    },
    {
        "name": "Ensure BLOB data type is not used",
        "id": 1106052,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Replace BLOB(n) data type with BYTEA data type."
        },
        "populations": null,
        "description": "This rule checks if any BLOB data type is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202023
        ],
        "children": []
    },
    {
        "name": "Ensure Database Links are not used",
        "id": 1106036,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Migrating database links from Oracle to PostgreSQL requires a full rewrite the mechanism that managed the database links."
        },
        "remediations": {
            "Agnostic": "PostgreSQL Usage\nQuerying data in remote databases in PostgreSQL is available via two primary options:\n1. dblink database link function.\n2. postgresql_fdw (Foreign Data Wrapper, FDW) extension.\n\nThe Postgres foreign data wrapper extension is new to PostgreSQL and offers functionality that is similar to dblink. However, the Postgres foreign data wrapper aligns closer with the SQL standard and can provide improved performance."
        },
        "populations": null,
        "description": "This rule checks if database links objects exists or are referenced in Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "KSDS VSAM Files: Programs/Utilities manipulating Data",
        "id": 1202042,
        "category": "TASK",
        "rationales": {
            "Azure": "KSDS stands for Key Sequenced Data Set, which is a type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. KSDS VSAM files are used to store and manage data in a sequential order based on a key field, which is used to uniquely identify each record in the file.\n\nIn KSDS VSAM files, records are stored based on their key values in ascending order, and each record has a unique key value. The records can be accessed directly using their key values, which makes KSDS VSAM files particularly useful for applications that require rapid access to specific records.\n\nKSDS VSAM files also support dynamic record sizing, which means that records can have different lengths, and records can be added or deleted from the file without having to reorganize the entire file.\n\nOverall, KSDS VSAM files have been widely used in IBM mainframe environments for many years as a reliable and efficient way to store and manage large volumes of data.\n\nWhen moving to Azure Cloud, VSAM files are, usually, replicated to Azure SQL Database \n\nVSAM has also many characteristics of a NO-SQL database and than can be moved to Cosmos DB \nhttps://azure.microsoft.com/mediahandler/files/resourcefiles/vsam-to-azure-cosmos-db/VSAM%20to%20Azure%20Cosmos%20DB.pdf) ",
            "Amazon Web Services": "KSDS stands for Key Sequenced Data Set, which is a type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. KSDS VSAM files are used to store and manage data in a sequential order based on a key field, which is used to uniquely identify each record in the file.\n\nIn KSDS VSAM files, records are stored based on their key values in ascending order, and each record has a unique key value. The records can be accessed directly using their key values, which makes KSDS VSAM files particularly useful for applications that require rapid access to specific records.\n\nKSDS VSAM files also support dynamic record sizing, which means that records can have different lengths, and records can be added or deleted from the file without having to reorganize the entire file.\n\nOverall, KSDS VSAM files have been widely used in IBM mainframe environments for many years as a reliable and efficient way to store and manage large volumes of data.\n\n\nWhen moving to AWS, VSAM files are, usually, replicated to Amazon RDS\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/migrate-and-replicate-vsam-files-to-amazon-rds-or-amazon-msk-using-connect-from-precisely.html",
            "Gougle Cloud Platform": "KSDS stands for Key Sequenced Data Set, which is a type of file organization used in the IBM Virtual Storage Access Method (VSAM) data storage system. KSDS VSAM files are used to store and manage data in a sequential order based on a key field, which is used to uniquely identify each record in the file.\n\nIn KSDS VSAM files, records are stored based on their key values in ascending order, and each record has a unique key value. The records can be accessed directly using their key values, which makes KSDS VSAM files particularly useful for applications that require rapid access to specific records.\n\nKSDS VSAM files also support dynamic record sizing, which means that records can have different lengths, and records can be added or deleted from the file without having to reorganize the entire file.\n\nOverall, KSDS VSAM files have been widely used in IBM mainframe environments for many years as a reliable and efficient way to store and manage large volumes of data."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "(EXISTS {MATCH (o:Object)-[:Property {value:'KSDS VSAM File'}]->(op:ObjectProperty)WHERE op.Id IN ['141023']})\n\nFor each KSDS VSAM dataset called by Cobol Program: KSDS VSAM dataset + Calling Program + ACCESS MODE\nFor each KSDS VSAM dataset called by Any Utility: KSDS VSAM dataset + Calling Any Utility + ACCESS MODE"
        },
        "description": "Listing CRUD (Create, Read, Update, Delete) operations is important to migrate KSDS VSAM files to the cloud because it helps to identify the specific operations that the application performs on the data stored in the VSAM files. \nThis information is critical in determining the appropriate cloud storage solution and configuring it to provide the necessary performance and reliability.\n\nList of all COBOL Programs calling KSDS VSAM file to identify access modes\nList of all utilities calling KSDS VSAM file to identify access modes",
        "impacts": [
            "replatform"
        ],
        "effort": "high",
        "parents": [
            1202006
        ],
        "children": []
    },
    {
        "name": "Avoid using MERGE",
        "id": 5060,
        "category": "TASK",
        "rationales": {
            "Agnostic": "COBOL merges are known to be inefficient on zOS environment. It is better to use external merge."
        },
        "remediations": {
            "Agnostic": "Remove all unnecessary MERGE action and replace them by external tool."
        },
        "populations": null,
        "description": "This rule searches for Cobol programs using the MERGE statement.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202022
        ],
        "children": []
    },
    {
        "name": "Access To IMS DB has been identfied",
        "id": 1202087,
        "category": "TASK",
        "rationales": {},
        "remediations": {},
        "populations": {
            "Mainframe": "Unknnow IMS PSB: CAST_IMS_ProgramSpecificationBlockPrototype\nUnknnow IMS PCB: CAST_IMS_ProgramControlBlockPrototype\n\nOR IMS PCB when not calling any IMS DB Segment.\n"
        },
        "description": "This rules identifies Unknnow IMS PSB and or Unknnow IMS PCB",
        "impacts": [],
        "effort": "high",
        "parents": [
            1202084
        ],
        "children": []
    },
    {
        "name": "Ensure GRAPHIC data type is not used",
        "id": 1106066,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Replace GRAPHIC(n) data type with CHAR(n) data type"
        },
        "populations": null,
        "description": "This rule checks if any GRAPHIC data type is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202023
        ],
        "children": []
    },
    {
        "name": "JCL Job/ JCL Procedure using TWS Scheduler",
        "id": 1202034,
        "category": "TASK",
        "rationales": {
            "Azure": "IBM Tivoli Workload Scheduler is the production workload manager for distributed platforms. \n\nAll JCL and programs using this scheduler should be identified to consider the new adoption or replacement with an equivalent cloud service. \n",
            "Amazon Web Services": "IBM Tivoli Workload Scheduler is the production workload manager for distributed platforms. Some of IBM's work to bring its product line into the AWS environment is underway. \n\nMore details can be found here https://aws.amazon.com/blogs/aws/ibm-tivoli-now-available-on-amazon-ec2/\n\nAll JCL and programs using this scheduler should be identified to consider the new adoption or replacement with an equivalent cloud service. ",
            "Gougle Cloud Platform": "IBM Tivoli Workload Scheduler is the production workload manager for distributed platforms. \n\nAll JCL and programs using this scheduler should be identified to consider the new adoption or replacement with an equivalent cloud service. \n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "JCL Job/Procedure calling 'TWS' utilities + Cobol program called by this JCL Job/Procedure\nTWS scheduler utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20tws"
        },
        "description": "Identify JCL Jobs and JCL Procedures calling TWS Scheduler Utilities\nIdentify Programs launched by these jobs",
        "impacts": [
            "rehost",
            "replatform",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202009
        ],
        "children": []
    },
    {
        "name": "Ensure PL/SQL package DBMS_OUTPUT is not used",
        "id": 1106012,
        "category": "TASK",
        "rationales": {
            "Agnostic": "The Oracle DBMS_OUTPUT package is typically used for debugging or for displaying output messages from PL/SQL procedures.\n\nAmazon Aurora PostgreSQL doesn’t currently provides a directly comparable alternative for Oracle DBMS_OUTPUT package."
        },
        "remediations": {
            "Agnostic": "You can use the PostgreSQL RAISE statement as an alternative to DBMS_OUTPUT.\n\nHave a look to github \"orafce\" project, maybe you can find a better remediation."
        },
        "populations": null,
        "description": "This rule checks the usage of the DBMS_OUTPUT package in Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "Ensure SQL server Scalar Function DATEADD is not used",
        "id": 1106134,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from SQL serevr to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Scalar Function DATEADD in SQL server should be replaced '+ INTERVAL 'X days/months/years'' in PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the usage of DATEADD Scalar Function in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure TINYINT data type is not used",
        "id": 1106116,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace TINYINT data type with SMALLINT data type"
        },
        "populations": null,
        "description": "This rule checks if any TINYINT data type is used in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "Ensure SQL Server DECLARE variable is not used",
        "id": 1106146,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from SQL Server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "Variable declarations statements used in DML files, stored procedures, functions and triggers should be converted before re-platforming your SQL Server Database to PostgreSQL:\n\nDECLARE @var [AS] type [= default_value] should be replaced with DECLARE var type [= | := | DEFAULT default_value]\nDECLARE @tab [AS] TABLE (…) should be replaced with CREATE TEMPORARY TABLE tab (…)."
        },
        "populations": null,
        "description": "This rule checks the variable declaration in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Function POSSTR is not used",
        "id": 1106078,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "POSSTR(<FIELD_1>, <FIELD_2>) in DB2 gets replaced by  POSITION(<FIELD_1> IN <FIELD_2>) in PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Function POSSTR is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Cobol Program using CICS transactions",
        "id": 1202148,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Usually, transactional programs are good candidates to be refactored and transformed into Lambda function."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "CICS_TRANSACTION and called Program"
        },
        "description": "This rule identifies COBOL programs called by COBOL Transactions",
        "impacts": [
            "retire",
            "review"
        ],
        "effort": "low",
        "parents": [
            1202152
        ],
        "children": []
    },
    {
        "name": "JCL Job/ JCL Procedure using CA-7 Scheduler (ISV  Broadcom)",
        "id": 1202031,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "CA-7 is a job scheduling/workflow automation tool packaged by ISV Broadcom. \n\nCA7 job scheduler can be migrated to Apache Airflow in AWS ( + additional service as Amazon S3 for the storage of Airflow DAGs and data files…) Or “Logic Apps Scheduler’ that provides triggers for starting and running workflows based on the interval and frequency of recurrence that user specifies.\n\n\nIdentifying the used scheduler and all JCL jobs, JCL procedures, and eventually Cobol Programs handled and monitored by this scheduler allows the migration team to assess the scope and complexity of the scheduling/workflow automation \ninfrastructure changes required to migrate to the cloud environment. So they can plan for all necessary changes and code refactoring to integrate the new cloud service replicating the CA-7 scheduler."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "CA-7 utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=like%20%25CA%257%25%20\nJCL Job/Procedure calling CA-7 utilities + Cobol program called by this JCL Job/Procedure"
        },
        "description": "Identify JCL Jobs and JCL Procedures calling CA-7 Scheduler Utilities\nIdentify Programs launched by these jobs",
        "impacts": [
            "replatform",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202009
        ],
        "children": []
    },
    {
        "name": "CICS Data Set: Programs/utilities manipulating data",
        "id": 1202064,
        "category": "TASK",
        "rationales": {
            "Agnostic": "CICS allows to access file data in several ways. Most file access is random in the online system because the transactions to be processed are not grouped and sorted in any order. \nTherefore, CICS supports the usual direct access methods - VSAM and DAM (direct access method). It also allows us to access the data using database managers.\n\nWhen mo"
        },
        "remediations": {
            "Azure": "Mainframe green screens not used can be directly retired safely.",
            "Agnostic": "Mainframe green screens not used can be directly retired safely.",
            "Amazon Web Services": "Mainframe green screens not used can be directly retired safely.",
            "Gougle Cloud Platform": "Mainframe green screens not used can be directly retired safely."
        },
        "populations": {
            "Mainframe": "search for nodes with type is one of (CICS_MAP, CICS_BMS, CICS_MAPSET, CAST_IMS_MessageFormatService, CAST_IMS_MessageInputDescriptor, CAST_IMS_MessageOutputDescriptor, CAST_CICS_MapPrototype, CAST_CICS_MapSetPrototype) and calling program"
        },
        "description": "This rule identifies COBOL programs calling CICS Data set",
        "impacts": [
            "retire",
            "review",
            "replatform"
        ],
        "effort": "high",
        "parents": [
            1202006
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Function LCASE is not used",
        "id": 1106076,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "LOWER(<FIELD>) (or) LCASE(<FIELD>) is supported in DB2 where as only LOWER(<FIELD>) is supported in PostgreSQL. Thus, if LCASE(<FIELD>) is used in DB2, then it should be changed to LOWER(<FIELD>) for PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Function LCASE is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Avoid using GOTO statement (COBOL)",
        "id": 5144,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Using GOTO code breaks the process execution flow and makes the code more difficult to understand and maintain."
        },
        "remediations": {
            "Agnostic": "Try to restructure the program and replace GOTO jumps with PERFORM."
        },
        "populations": null,
        "description": "This rule searches for Cobol programs using GOTO statements to manage the control flow. The \"GOTO\" statement of embedded SQL is not taken into account.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202022
        ],
        "children": []
    },
    {
        "name": "Cobol Programs using IBM MQSeries - MQ Utilities",
        "id": 1202020,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying COBOL programs using IBM MQ utilities allows the migration team to assess the scope and complexity of the messaging infrastructure changes required to support these programs in the cloud. So they can plan for all necessary changes and code refactoring to integrate the new cloud service replicating IBM MQSeries."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Cobol Programs (InternalType=CAST_COBOL_SavedProgram) calling MQ utilities\nJCL Job or JCL Procedure Calling MQ utilities"
        },
        "description": "Identify all Cobol Programs, JCL Jobs and JCL Procedures Calling an IBM MQ Utility",
        "impacts": [
            "rehost",
            "replatform",
            "review",
            "refactor"
        ],
        "effort": "moderate",
        "parents": [
            1202066
        ],
        "children": []
    },
    {
        "name": "Avoid using ALTER",
        "id": 5062,
        "category": "TASK",
        "rationales": {
            "Agnostic": "The ALTER statement is error-prone. If it is used in Cobol programs, then GO TO statements as they appear in the listing may not be those that will be encountered by the program at run time. The ALTER statement makes the maintenance programmer's job more difficult."
        },
        "remediations": {
            "Agnostic": "If you need to change the processing sequence due to a certain condition, then use an alternative set of PERFORM or GO TO statements."
        },
        "populations": null,
        "description": "This rule searches for Cobol programs using ALTER statements to manage their control flow.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202021
        ],
        "children": []
    },
    {
        "name": "Identify application's adherence to Focus technology",
        "id": 1202098,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "The presence of the Focus code influences the migration strategy. Focus Technology may has unique considerations during modernization, such as conversion to a higher-level language, rewriting, or reengineering. Understanding the extent of Focus code allows you to design an appropriate migration plan that addresses these specific requirements.\n\nFor the conversion of the code, the presence of the Focus technology will also guide the choice of the partner and tool as the conversion of Focus is not systematically supported"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All objects of Focus technology  + callers & callees \nInternal types : FOCUSTable OR FOCUSTablef OR FOCUSDefine OR FOCUSMatch OR FOCUSGraph OR FOCUSJoin OR FOCUSMaster OR FOCUSprocedure"
        },
        "description": "This rule checks all Focus objects and the adherence to the application",
        "impacts": [
            "refactor",
            "rehost"
        ],
        "effort": "high",
        "parents": [
            1202099
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Function DATE is not used",
        "id": 1106072,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Converts the input to date value :\nDATE('2006-09-21') in DB2 to be changed to TO_DATE('21-02-2006','DD-MMYYYY') in PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Function DATE is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 SET variable is not used",
        "id": 1106108,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "Converting Variable setting statements used in stored procedures, functions and triggers from IBM DB2 to PostgreSQL as follows: \n\n1    SET v1 = value   To be replaced by   v1 := value\n2    SET v1 = value, v2 = value2, …   To be replaced by   v1 := value; v2 := value2; …\n3    SET (v1, v2, …) = (value, value2, …)   To be replaced by   v1 := value; v2 := value2; …\n4    SET (v1, v2, …) = (SELECT c1, c2, …)   To be replaced by   SELECT c1, c2, … INTO v1, v2, …"
        },
        "populations": null,
        "description": "This rule checks the variable assignment in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025,
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure SQL server Scalar Function ISNULL is not used",
        "id": 1106140,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from SQL serevr to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Scalar Function ISNULL SQL server should be replaced with a specified NULL  value: COALESCE(exp, replacement)"
        },
        "populations": null,
        "description": "This rule checks the usage of ISNULL Scalar Function in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Function RAND is not used",
        "id": 1106080,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "RAND() in DB2 get replaced by RANDOM() in PostgreSQL and Returns a pseudorandom floating-point value in the range of zero to one inclusive."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Function RAND is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Ensure NVARCHAR data type is not used",
        "id": 1106124,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace NVARCHAR(n)  data type with VARCHAR(n)  data type\nReplace NVARCHAR(max)  data type with TEXT  data type"
        },
        "populations": null,
        "description": "This rule checks if any NVARCHAR data type is used in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "Ensure Invisible Index is not used",
        "id": 1106042,
        "category": "TASK",
        "rationales": {
            "Agnostic": "PostgreSQL does not support Invisible Indexes"
        },
        "remediations": {
            "Agnostic": "Currently, PostgreSQL does not provide a directly comparable alternative for Oracle Invisible Indexes."
        },
        "populations": null,
        "description": "This rule checks if any Invisible Indexes exists in Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "Cobol Programs Publishing Messages to IBM MQ",
        "id": 1202049,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying COBOL programs that publish messages to queues allows the migration team to assess the scope and complexity of the messaging infrastructure changes required to support these programs in the cloud."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Cobol Programs publishing Messages to queue  : InternalType= 'CAST_COBOL_SavedProgram' calling a 'CAST_COBOL_MQ_Publisher'"
        },
        "description": "Cobol Programs publishing Messages to queue: Cobol Program calling an IBM MQ Publisher",
        "impacts": [
            "rehost",
            "replatform",
            "review",
            "refactor"
        ],
        "effort": "moderate",
        "parents": [
            1202066
        ],
        "children": []
    },
    {
        "name": "Ensure DATETIMEOFFSET data type is not used",
        "id": 1106130,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace DATETIMEOFFSET(p) data type with TIMESTAMP(p) WITH TIME ZONE"
        },
        "populations": null,
        "description": "This rule checks if any DATETIMEOFFSET(p) data type is used in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "JCL Job/Cobol Program using 3rd Party Products/tools : AR/CTL (ISV BMC)",
        "id": 1202037,
        "category": "TASK",
        "rationales": {
            "Agnostic": "AR/CTL products provide facilities for security implementation of application programs that run in the z/OS system environment. During application migration to the cloud, this tool will be likely mapped to equivalent cloud Service ( AWS Identity and Access Management (IAM) can be an Alternative service). All JCL/programs using this tool need to identified to consider adoption and deployment with new service."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "AR/CTL utilitis \nhttp://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20ctl\nJCL Job/Procedure calling AR/CTL utilities + Cobol program called by this JCL Job/Procedure"
        },
        "description": "",
        "impacts": [
            "rehost",
            "replatform",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202010
        ],
        "children": []
    },
    {
        "name": "Ensure NCHAR VARYING data type is not used",
        "id": 1106064,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Replace NCHAR VARYING(n) data type with VARCHAR(n) data type"
        },
        "populations": null,
        "description": "This rule checks if any NCHAR VARYING data type is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202023
        ],
        "children": []
    },
    {
        "name": "Identify application's adherence to Assembler technology",
        "id": 1202078,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "The presence of the Assembler code influences the migration strategy. Assembler programs may have unique considerations during modernization, such as conversion to a higher-level language, rewriting, or reengineering. Understanding the extent of Assembler code allows you to design an appropriate migration plan that addresses these specific requirements.\n\nFor the conversion of the code, the presence of the assembler technology will also guide the choice of the partner and tool as the conversion of the assembler is not systematically supported"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "All objects of Assembler technology  + callers & callees \nInternal types : ASMZOSProgram ( ID= 2043005) OR ASM_MACRO (ID=2043007) OR CallTo_program (ID=\"2043006)"
        },
        "description": "This rule checks all assembler objects and the adherence to the application",
        "impacts": [
            "refactor",
            "rehost"
        ],
        "effort": "high",
        "parents": [
            1202096
        ],
        "children": []
    },
    {
        "name": "GDG Files: Programs/Utilities manipulating Data",
        "id": 1202015,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Please review each Cobol Program reading/writing in GDG Dataset in order to plan replacement using SQL statements.\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "GDG dataset : (EXISTS {MATCH (o:Object)-[:Property {value:'GDG Dataset'}]->(op:ObjectProperty)WHERE op.Id IN ['141023']})\n\n\nFor each GDG dataset called by Cobol Program: GDG dataset + Calling Program + ACCESS MODE\nFor each GDG dataset called by Any Utility: GDG dataset + Calling Any Utility + ACCESS MODE"
        },
        "description": "For Each used GDG Dataset, we display the access mode(s) (Read/Write mode) and Calling Cobol Program",
        "impacts": [
            "replatform",
            "rehost",
            "refactor"
        ],
        "effort": "moderate",
        "parents": [
            1202013
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Function CHAR is not used",
        "id": 1106084,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "CHAR in DB2 should be replaced by TO_CHAR( <timestamp / interval / int / double precision / numeric type>, text) in PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Function CHAR is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "JCL Job/JCL Procedure doing Data Transfer with EzSocket Protocol",
        "id": 1202036,
        "category": "TASK",
        "rationales": {
            "Agnostic": "JCL jobs and Procedures doing data and/or file transfer should be identified and also dependent programs. When moving to cloud platform, this protocol is replaced with cloud-native data transfer tool. Minimal Code changes or refactoring are necessary to integrate the equivalent cloud native service."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "EzSocket utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20EzSocket%20 \nJCL Job/JCL Procedure calling EzSocket utilities + Cobol Programs calling these JCL Job/JCL Procedure"
        },
        "description": "Identify JCL Jobs and JCL Procedure calling EzSocket utilities",
        "impacts": [
            "rehost",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202008
        ],
        "children": []
    },
    {
        "name": "Ensure VALUES statement is not used",
        "id": 1106106,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "DB2 VALUES statement should be replaced in PostgresSQL with SELECT ... UNION ALL SELECT ..."
        },
        "populations": null,
        "description": "This rule checks the usage of the VALUES statement in the DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Green screen accessed by program linked to MQ utilities",
        "id": 1202061,
        "category": "TASK",
        "rationales": {
            "Agnostic": "If the selected program has linked to MQ system, you will have to expose an API if you plan having a web app instead of the green screen."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Green screen accessed by Transactional program Calling MQ utilities \nMQ utility http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=like%20%25MQ%25utility%25"
        },
        "description": "This rule checks any CICS Map, CICS Map definition or CICS Mapset accessed by a COBOL program with access to any MQ publisher ou Receiver",
        "impacts": [
            "retire"
        ],
        "effort": "high",
        "parents": [
            1202058,
            1202063
        ],
        "children": []
    },
    {
        "name": "Ensure Unused Column is not used",
        "id": 1106038,
        "category": "TASK",
        "rationales": {
            "Agnostic": "PostgreSQL doesn’t support marking table columns as unused."
        },
        "remediations": {
            "Agnostic": "PostgreSQL doesn’t support marking table columns as unused. However, when running the ALTER TABLE… DROP COLUMN command, the drop column statement doesn’t physically remove the column; it only makes it invisible to SQL operations"
        },
        "populations": null,
        "description": "This rule checks if any Column table is set as Unused in the Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202047
        ],
        "children": []
    },
    {
        "name": "Missing IMS Segment",
        "id": 1202086,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying IMS segments, their access mode and eventually their relationships can help understanding the design of the appropriate relational database schema.\n\n\nCobol programs that access IMS DB will need to be modified to interact with the new relational database. By identifying the programs and their dependencies on IMS DB, you can plan and implement the necessary changes in the application code, such as updating SQL queries or data access logic.\n\n\n\n\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "IMS Segment (InternalType: CAST_IMS_SegmentPrototype ) \nFor Each Segment, provides the PCB calling  (InternalType: CAST_IMS_DatabaseProgramControlBlock) + Calling Cobol Program \n\n"
        },
        "description": "This rules identifies Missing IMS Segments that have been identfied in the application  and Progams accessing these segments via PCB/PSB.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202084
        ],
        "children": []
    },
    {
        "name": "JCL Job/ JCL Procedure using EPS Scheduler",
        "id": 1202033,
        "category": "TASK",
        "rationales": {
            "Agnostic": "EPS (Execution Processing System) Scheduler is a job scheduling software for mainframe computers. It is a product of CA Technologies. The EPS Scheduler is designed to manage batch processing jobs on a mainframe system. It provides a centralized interface for scheduling, monitoring, and managing batch jobs.\n\n\n\nIdentifying the used scheduler and all JCL jobs, JCL procedures, and eventually Cobol Programs handled and monitored by this scheduler allows the migration team to assess the scope and complexity of the scheduling/workflow automation \ninfrastructure changes required to migrate to the cloud environment. So they can plan for all necessary changes and code refactoring to integrate the new cloud service replicating the EPS scheduler.\n\n\n\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Cobol Program calling ESP Sceduler utilities\nESP Scheduler : http://rulesmanager/techno-guru/#page=1&sort=popularity&technology2=like%20%25ESP%25\nJCL Job/Procedure calling 'EPS' utilities + Cobol program called by this JCL Job/Procedure"
        },
        "description": "Identify JCL Jobs and JCL Procedures calling EPS Scheduler Utilities\nIdentify Programs launched by these jobs",
        "impacts": [
            "refactor",
            "rehost",
            "replatform",
            "review"
        ],
        "effort": "moderate",
        "parents": [
            1202009
        ],
        "children": []
    },
    {
        "name": "Ensure MERGE statement is not used",
        "id": 1106002,
        "category": "TASK",
        "rationales": {
            "Agnostic": "MERGE statement is not supported and it cannot be automatically converted by AWS SCT. Manual conversion is straight-forward in most cases."
        },
        "remediations": {
            "Agnostic": "PostgreSQL does not support the usage of MERGE SQL statement. \nAs an alternative, consider using the INSERT… ON CONFLICT clause, which can handle cases where insert clauses might cause a conflict, and then redirect the operation as an update."
        },
        "populations": null,
        "description": "This rule checks if Oracle MERGE Statement is used.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202047
        ],
        "children": []
    },
    {
        "name": "Ensure PL/SQL package DBMS_AUTO_INDEX is not used",
        "id": 1106014,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Package DBMS_AUTO_INDEX is used to configure auto indexes and generate reports.\nPostgreSQL does not provide an Automatic Indexing feature.\n\nIn self-managed PostgreSQL instances, extensions like Dexter (https://github.com/ankane/dexter) and HypoPG (https://hypopg.readthedocs.io/en/latest/ ) can be utilized for generating indexes with limitations. Amazon Aurora PostgreSQL does not support these extensions."
        },
        "remediations": {
            "Agnostic": "Remove References to DBMS_AUTO_INDEX and replace with PostgreSQL Solution.\n\nPostgreSQL does not provide Automatic Indexing feature, but in self-managed PostgreSQL instances, extensions like Dexter (https://github.com/ankane/dexter) and HypoPG (https://hypopg.readthedocs.io/en/latest/ ) can\nbe utilized for generating indexes with limitations (Amazon Aurora PostgreSQL does not support these extensions).\nThe approach taken by these extensions are :\n- Identify the queries.\n- Update the table statistics if they haven’t been analyzed recently.\n- Get the initial cost of the queries and create hypothetical indexes on columns that aren’t already indexes.\n- Get costs again and see if any hypothetical indexes were used. Hypothetical indexes that were used and significantly reduced cost are selected to be indexes."
        },
        "populations": null,
        "description": "This rule checks the usage or DBMS_AUTO_INDEX package in Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Functions DAY/DAYS are not used",
        "id": 1106092,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "DAY returns the day (as in day of the month) part of a date (or equivalent) value. The output format is integer.\nDAY (<DATE_FIELD>) should be replaced with : DATE_PART(‘day’, <DATE_FIELD>).\n\nDAYS converts a date (or equivalent) value into a number that represents the number of days since the date \"0001-01-01\" inclusive. The output format is integer.\nDAYS is not available in PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Functions DAY/DAYS are used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Green Screen access by program linked to database storage",
        "id": 1202057,
        "category": "TASK",
        "rationales": {
            "Agnostic": "If the selected program has access to database storage, you will have to expose an API if you plan to have a web app instead of the green screen."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Green screen accessed by program calling object of type ( DB objects )"
        },
        "description": "This rule checks any CICS Map, CICS Map definition or CICS Mapset accessed by a COBOL program with access to any DB objects",
        "impacts": [
            "refactor"
        ],
        "effort": "high",
        "parents": [
            1202058,
            1202063
        ],
        "children": []
    },
    {
        "name": "Ensure VARCHAR(n) FOR BIT DATA data type is not used",
        "id": 1106058,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Replace VARCHAR(n) FOR BIT DATA data type with BYTEA data type."
        },
        "populations": null,
        "description": "This rule checks if any VARCHAR(n) FOR BIT DATA data type is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202023
        ],
        "children": []
    },
    {
        "name": "Green screen accessed by program linked to datafile storage",
        "id": 1202062,
        "category": "TASK",
        "rationales": {
            "Agnostic": "If the selected program has an access to data file storage, you will have to expose an API if you plan having a web app instead of the green screen."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Green screen accessed by program calling object of type ( DB2 objects - JCL data set file)"
        },
        "description": "This rule checks any CICS Map, CICS Map definition or CICS Mapset accessed by a COBOL program with access to any Data set file",
        "impacts": [
            "refactor"
        ],
        "effort": "high",
        "parents": [
            1202058,
            1202063
        ],
        "children": []
    },
    {
        "name": "Ensure PL/SQL package UTL_FILE is not used",
        "id": 1106006,
        "category": "TASK",
        "rationales": {
            "Agnostic": "PostgreSQL doesn’t currently provide a directly comparable alternative for the Oracle UTL_FILE package."
        },
        "remediations": {
            "Agnostic": "PostgreSQL doesn’t currently provide a directly comparable alternative for the Oracle UTL_FILE package."
        },
        "populations": null,
        "description": "This rule checks the usage of the UTL_FILE package in the Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "Avoid using PREPARE STMT statement (Dynamic SQL) with STRING containing HOST variables",
        "id": 8480,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Injection flaws, such as SQL, NoSQL, OS, and LDAP injection, occur when untrusted data is sent to an interpreter as part of a command or query. The attacker's hostile data can trick the interpreter into executing unintended commands or accessing data without proper authorization."
        },
        "remediations": {
            "Agnostic": "The PREPARE STMT statement having STRING as a parameter must not contain host variables."
        },
        "populations": null,
        "description": "Input host variables are used to specify data to be transferred from the COBOL program to the database\n\nHost variables are considered data, not part of the SQL code, which is safe against SQL injection attacks. But dynamic SQL (PREPARE or EXECUTE IMMEDIATE) is allowed, and binding does not prevent the injection of code.\n\nThis rule checks for PREPARE STMT statement having STRING passed in parameter and containing host variables.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202021
        ],
        "children": []
    },
    {
        "name": "Unknown CICS Transactions",
        "id": 1202149,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Usually, transactional programs are good candidates to be refactored and transformed into Lambda functions.\n"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "CAST_CICS_TransactionPrototype and called Program\n"
        },
        "description": "This rule identifies unknown COBOL Transactions and called programs",
        "impacts": [
            "refactor"
        ],
        "effort": null,
        "parents": [
            1202152
        ],
        "children": []
    },
    {
        "name": "Ensure READ ONLY Table is not used",
        "id": 1106040,
        "category": "TASK",
        "rationales": {
            "Agnostic": "READ ONLY mode for Table is not supported by PostgreSQL."
        },
        "remediations": {
            "Agnostic": "PostgreSQL does not provide an equivalent to the READ ONLY mode supported in Oracle.\nThe following alternatives could be used as workarounds:\nl “Read-only” User or Role.\nl “Read-only” database.\nl Creating a “read-only” database trigger or a using a “read-only” constraint."
        },
        "populations": null,
        "description": "This rule checks if any READ ONLY table exists in Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "JCL Job/Cobol Program using 3rd Party Products/tools : CA-View (SAR)",
        "id": 1202073,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "CA-View (Formerly known as SAR), a SYSOUT Archival and Retrieval system, is a facility for storing and retrieving computer output.\nIt can be replaced by a cloud-native solution as LRS printing solution on AWS.\nAll JCL/programs using this tool need to be identified to consider adoption and deployment with new cloud service/solution"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "JCL Job/Procedure calling 'StreamWeaver' utilities + Cobol program called by this JCL Job/Procedure\nStream Weaver Utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20StreamWeaver"
        },
        "description": "",
        "impacts": [
            "replatform",
            "review"
        ],
        "effort": "high",
        "parents": [
            1202044
        ],
        "children": []
    },
    {
        "name": "Ensure CLOB data type is not used",
        "id": 1106054,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Replace CLOB(n) data type with TEXT data type."
        },
        "populations": null,
        "description": "This rule checks the usage of CLOB Storage and the explicit conversion function TO_CLOB which convert other data types to CLOB.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202023
        ],
        "children": []
    },
    {
        "name": "Ensure IDENTITY Columns is not used",
        "id": 1106142,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from SQL Server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "The IDENTITY property allows you to automatically assign incremental integer values to a column. In PostgreSQL you can use the GENERATED AS IDENTITY property."
        },
        "populations": null,
        "description": "This rule checks the usage of IDENTITY Columns in CREATE TABLE statement in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202178
        ],
        "children": []
    },
    {
        "name": "Avoid using \"REDEFINES\" in the Cobol data structures",
        "id": 1202072,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As part of mainframe modernization, when VSAM files are migrated to relational databases, if REDEFINES clause is used cobol datas structure, it needs to be handled since REDEFINES Clause allows to name a computer storage area with different names."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "http://rulesmanager/#:-4:5v"
        },
        "description": "This rule searches for Cobol programs using the MERGE statement.",
        "impacts": [
            "rehost"
        ],
        "effort": "low",
        "parents": [
            1202022
        ],
        "children": []
    },
    {
        "name": "Ensure FLOAT data type is not used",
        "id": 1106068,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "Replace FLOAT(p) data type with DOUBLE PRECISION data type."
        },
        "populations": null,
        "description": "This rule checks if any FLOAT data type is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202023
        ],
        "children": []
    },
    {
        "name": "Ensure ROWVERSION data type is not used",
        "id": 1106122,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace ROWVERSION data type with BYTEA data type"
        },
        "populations": null,
        "description": "This rule checks if any ROWVERSION data type is used in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 DECLARE variable is not used",
        "id": 1106102,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "Variable declarations statements used in DML files, stored procedures, functions and triggers should be converted before re-platforming your DB2 Database to PostgreSQL:\n\n1- Declarations are inside BEGIN END block   Should be before BEGIN END block\n2- DECLARE var datatype DEFAULT value        Should be replaced by var datatype DEFAULT value\n3- DECLARE var, var2, … datatype   Should be replaced by  var datatype; var2 datatype; …"
        },
        "populations": null,
        "description": "This rule checks the variable declaration in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "Ensure you don't have unsupported option GENERATED BY DEFAULT for identity columns",
        "id": 1106022,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identity Columns with GENERATED BY DEFAULT option are not supported by PostgreSQL. But PostgreSQL suggests a specific way to create an autoincrementing column as equivalent feature"
        },
        "remediations": {
            "Agnostic": "PostgreSQL enables you to create a sequence that is similar to the IDENTITY property supported by Oracle 12c identity column feature. When creating a new table using the SERIAL pseudo-type, a sequence is created.\n\nAdditional types from the same family are SMALLSERIAL and BIGSERIAL.\nBy assigning a SERIAL type to a column as part of table creation, PostgreSQL creates a sequence using default configuration and adds the NOT NULL constraint to the column. The new sequence can be altered and configured as a regular sequence.\n\nSince PostgreSQL 10, there is a new option called identity columns which is similar to SERIAL data type but more SQL standard compliant. The identity columns are highly compatibility compare to Oracle identity columns."
        },
        "populations": null,
        "description": "This rule checks if tables with identity columns has GENERATED BY DEFAULT option in Oracle Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202047
        ],
        "children": []
    },
    {
        "name": "Ensure SQL server Scalar Function GETDATE is not used",
        "id": 1106138,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from SQL serevr to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Scalar Function GETDATE in SQL server should be replaced by NOW() in PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the usage of GETDATE Scalar Function in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure NCHAR data type is not used",
        "id": 1106128,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace NCHAR(n) data type with CHAR(n) data type"
        },
        "populations": null,
        "description": "This rule checks if any NCHAR data type is used in SQL server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "Ensure DB2 Scalar Function SMALLINT is not used",
        "id": 1106074,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error."
        },
        "remediations": {
            "Agnostic": "In DB2, SMALLINT converts either a number or a valid character value into a smallint value.SMALLINT(<Decimal Number>) in DB2 gets replaced by TO_NUMBER(<field>, <format>) in PostgreSQL."
        },
        "populations": null,
        "description": "This rule checks the DB2 Scalar Function SMALLINT is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202025
        ],
        "children": []
    },
    {
        "name": "JCL Job/JCL Procedure doing Data Transfer with FTP Protocol",
        "id": 1202039,
        "category": "TASK",
        "rationales": {
            "Azure": "The FTP protocol in z/OS has many similarities to FTP on other platforms. There are some aspects of FTP on z/OS® that are unique to the z/OS® platform.\n\n\nWhen moving mainframe applications using FTP protocol for data transfer, many changes and modifications will be required to adapt this protocol to the cloud environment specifications \n\nIdentifying the protocol beforehand and all JCL jobs and programs involved can help ensure to asses complexity of the Integration of data transfer services/protocols on the target cloud environment.",
            "Amazon Web Services": "The FTP protocol in z/OS has many similarities to FTP on other platforms. There are some aspects of FTP on z/OS® that are unique to the z/OS® platform.\n\nUsing FTP protocol in AWS environment will require integration of additional AWS native services as identity providers and AWS storage services that can be used to store and access data over the selected protocol (Amazon S3 to store and access files as objects over the selected protocol or Amazon EFS to store and access your files system over the selected protocol). \n\nIntegration of these services will require code change for all JCL Jobs and Cobol Programs using FTP Protocol",
            "Gougle Cloud Platform": "The FTP protocol in z/OS has many similarities to FTP on other platforms. There are some aspects of FTP on z/OS® that are unique to the z/OS® platform.\n\n\nWhen moving mainframe applications using FTP protocol for data transfer, many changes and modifications will be required to adapt this protocol to the cloud environment specifications \n\nIdentifying the protocol beforehand and all JCL jobs and programs involved can help ensure to asses complexity of the Integration of data transfer services/protocols on the target cloud environment."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "FTP utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20FTP\nJCL Job/JCL Procedure calling FTP utilities"
        },
        "description": "Identify JCL Jobs and JCL Procedure calling FTP utilities",
        "impacts": [
            "rehost",
            "review",
            "replatform"
        ],
        "effort": "moderate",
        "parents": [
            1202008
        ],
        "children": []
    },
    {
        "name": "IMS GSAM Files:  Programs/Utilities manipulating Data",
        "id": 1202093,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying IMS GSAM, their access mode and eventually their relationships can help understanding the design of the appropriate relational database schema.\n\n\nCobol programs that access IMS GSAM will need to be modified to interact with the new relational database. By identifying the programs and their dependencies on IMS GSAM Datasets, you can plan and implement the necessary changes in the application code, such as updating SQL queries or data access logic."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "GSAM DataSet (InternalType OR CAST_IMS_AnalyzedSegment)\nFor Each Segment, provides the PCB calling  (InternalType: CAST_IMS_DatabaseProgramControlBlock) + Calling Cobol Program\n\n"
        },
        "description": "This rule identifies the IMS GSAM DataSet used in the application and Progams accessing these Datasets.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202006
        ],
        "children": []
    },
    {
        "name": "Ensure MERGE statement is not used",
        "id": 1106110,
        "category": "TASK",
        "rationales": {
            "Agnostic": "MERGE statement is not supported and it cannot be automatically converted. Manual conversion is straightforward in most cases."
        },
        "remediations": {
            "Agnostic": "PostgreSQL ( until version 15) doesn’t support the use of the MERGE command. As an alternative, consider using the INSERT… ON CONFLICT clause, which can handle cases where insert clauses might cause a conflict, and then redirect the operation as an update."
        },
        "populations": null,
        "description": "This rule checks if MERGE Statement is used in SQL server files and Embedded SQL Queries.",
        "impacts": [],
        "effort": null,
        "parents": [
            1202179
        ],
        "children": []
    },
    {
        "name": "Ensure NTEXT data type is not used",
        "id": 1106126,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from the SQL server to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to an error"
        },
        "remediations": {
            "Agnostic": "Replace NTEXT data type with TEXT data type"
        },
        "populations": null,
        "description": "This rule checks if any TEXT data type is used in SQL Server Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202177
        ],
        "children": []
    },
    {
        "name": "Cobol Programs Subsribing to IBM MQ",
        "id": 1202050,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying COBOL programs that subscribe to an MQ allows the migration team to assess the scope and complexity of the messaging infrastructure changes required to support these programs in the cloud."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "Cobol Programs subscribing to a MQ: InternalType= CAST_COBOL_SavedProgram called by 'CAST_COBOL_MQ_Subscriber'\n"
        },
        "description": "identify Cobol Programs subscribing to an IBM MQ: Cobol Program called by an IBM MQ Subscriber",
        "impacts": [
            "rehost",
            "replatform",
            "review",
            "refactor"
        ],
        "effort": "moderate",
        "parents": [
            1202066
        ],
        "children": []
    },
    {
        "name": "Ensure PL/SQL package Oracle UTL_MAIL or UTL_SMTP is not used",
        "id": 1202083,
        "category": "TASK",
        "rationales": {
            "Amazon Web Services": "Amazon Aurora PostgreSQL doesn’t provide native support for sending email message from the database. \nFor alerting purposes, use the Event Notification Subscription feature to send email notifications to operators.\nplease refer to the section 'Oracle UTL_MAIL or UTL_SMTP and PostgreSQL Scheduled Lamda with SES' in the following page:\n\nhttps://docs.aws.amazon.com/dms/latest/oracle-to-aurora-postgresql-migration-playbook/chap-oracle-aurora-pg.sql.mail.html\n"
        },
        "remediations": {},
        "populations": {
            "SQL": "http://rulesmanager/#:1n:2xe"
        },
        "description": "This rule checks the usage of the Oracle UTL_MAIL or UTL_SMTP packages in the Oracle Database(s).",
        "impacts": [
            "replatform"
        ],
        "effort": "moderate",
        "parents": [
            1202176
        ],
        "children": []
    },
    {
        "name": "GDG Files defined but not used",
        "id": 1202030,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying defined Datased that are not used for data Storage is useful to optimize migration effort and cost. \nThese datasets may be the symptom of Dead Code and so good candidates to be retired"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "GDG Dataset : (EXISTS {MATCH (o:Object)-[:Property {value:'GDG Dataset'}]->(op:ObjectProperty)WHERE op.Id IN ['141023']})\n\n\nGDG dataset Called by Cobol Program with DEFINE link ONLY\nGDG dataset called ONLY by JCL Steps"
        },
        "description": "This rule checks GDG Files defined but not used for data storage.",
        "impacts": [
            "retire",
            "refactor",
            "replatform",
            "rehost"
        ],
        "effort": "moderate",
        "parents": [
            1202013
        ],
        "children": []
    },
    {
        "name": "JCL Job/JCL Procedure doing Data Transfer with NDM Protocol",
        "id": 1202040,
        "category": "TASK",
        "rationales": {
            "Azure": "Connect:Direct—originally named Network Data Mover (NDM) is a computer software product that transfers files between mainframe computers and/or midrange computers.\n\n\nAll JCL Jobs and/or Procedures using NDM Protocol need to be identified and reviewed to check the compatibility of used utilities and to ensure integration with Equivalent AWS native service for data transfer.",
            "Amazon Web Services": "Connect:Direct—originally named Network Data Mover (NDM) is a computer software product that transfers files between mainframe computers and/or midrange computers.\n\n\nIBM Sterling Connect:Direct 5.3.0 introduces support for reading and writing data using the Amazon S3 Object Store. (https://www.ibm.com/docs/en/connect-direct/5.3.0?topic=usospcdu-setting-up-connectdirect-node-s3-object-store-providers)\n\n\nAll JCL Jobs and/or Procedures using NDM Protocol need to be identified and reviewed to check the compatibility of used utilities and to ensure integration with Equivalent AWS native service for data transfer.",
            "Gougle Cloud Platform": "Connect:Direct—originally named Network Data Mover (NDM) is a computer software product that transfers files between mainframe computers and/or midrange computers.\n\n\nAll JCL Jobs and/or Procedures using NDM Protocol need to be identified and reviewed to check the compatibility of used utilities and to ensure integration with Equivalent AWS native service for data transfer."
        },
        "remediations": {},
        "populations": {
            "Mainframe": "JCL Job/JCL Procedure calling  NDMutilities\nNDM utilities : http://rulesmanager/techno-guru/#page=1&sort=popularity&technologies=match%20NDM"
        },
        "description": "Identify JCL Jobs and JCL Procedure calling NDM utilities",
        "impacts": [
            "rehost",
            "review",
            "replatform",
            "refactor"
        ],
        "effort": "moderate",
        "parents": [
            1202008
        ],
        "children": []
    },
    {
        "name": "Ensure DECFLOAT data type is not used",
        "id": 1106070,
        "category": "TASK",
        "rationales": {
            "Agnostic": "As you decide to migrate from DB2 to PostgreSQL, it is important to note the changes to be taken care of during the migration process. Without adaptation, the SQL script won’t compile on Postgresql, leading to error"
        },
        "remediations": {
            "Agnostic": "Replace DECFLOAT(16|34) data type with FLOAT data type."
        },
        "populations": null,
        "description": "This rule checks if any DECFLOAT data type is used in DB2 Database(s).",
        "impacts": [],
        "effort": null,
        "parents": [
            1202023
        ],
        "children": []
    },
    {
        "name": "PDS Files Defined but not used",
        "id": 1202048,
        "category": "TASK",
        "rationales": {
            "Agnostic": "Identifying defined Datased that are not used for data Storage is useful to optimize migration effort and cost. \nThese datasets may be the symptom of Dead Code and so good candidates to be retired"
        },
        "remediations": {},
        "populations": {
            "Mainframe": "(EXISTS {MATCH (o:Object)-[:Property {value:'PDS Dataset'}]->(op:ObjectProperty)WHERE op.Id IN ['141023']})\n\nPDS dataset Called by Cobol Program with DEFINE link ONLY\nPDS dataset called ONLY by JCL Steps\n\n"
        },
        "description": "This rule checks PDS Files defined but not used for data storage.",
        "impacts": [
            "refactor",
            "replatform"
        ],
        "effort": "low",
        "parents": [
            1202013
        ],
        "children": []
    }
]